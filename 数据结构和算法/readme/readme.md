





# 数据结构和算法

业务开发工程师，CRUD（增删改查） boy 😭😭😭

<u>目标</u>：不能重复地堆砌业务逻辑，要有难度递进，提升能力，写出达到开源水平的框架。

数据结构指的是“一组数据的存储结构”，算法指的是“操作数据的一组方法”。

数据结构是为算法服务的，算法是要作用再特定的数据结构上的。

效率和资源消耗的度量衡--复杂度分析。

<u>总览</u>：

![](/Users/yangzanjie/code/study/数据结构和算法/数据结构和算法.jpg)

------



## 1 常用数据结构和算法

<u>10个数据结构</u>：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie树。

<u>10个算法</u>：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法。

<u>学习技巧</u>：

- 边学边练，适度刷题：建议每周1-2小时时间，自己实现数据结构和算法，刷题适度。
- 多问、多思考、多互动。
- 坚持：打怪升级学习法，设立切实可行的目标，一点点提高。
- 耐心：学习知识，反复迭代，不断沉淀。

------



## 2 复杂度分析一

### 2.1 事后统计法

指通过统计、监控等方式，得到算法执行的时间和占用的你内存大小。

局限性大。

- 测试结果非常依赖测试环境。
- 测试结果受数据规模的影响很大。

### 2.2 大O复杂度表示法

#### 2.2.1 概念

算法执行效率，即代码执行时间（粗略讲）。

`T(n)=O(f(n))`

T(n)表示代码执行的时间；n表示数据的规模大小；f(n)表示每行代码执行的次数总和；O表示代码的执行时间T(n)与f(n)成正比。

<u>大O时间复杂度表示法，并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，故也叫作渐进时间复杂度，简称时间复杂度。</u>

n很大时，公式中的高阶项成为主导，因此只记录最大一个量级。

例如：T(n)=O(n)、T(n)=O(n^2)

#### 2.2.2 时间复杂度分析

- 只关注循环执行次数最多的一段代码

```c++
int cal(int n) {
   int sum = 0;
   int i = 1;
   for (; i <= n; ++i) {
     sum = sum + i;
   }
   return sum;
 }
```

在这里，只关注第4、5行代码，时间复杂度O(n)。

- 加法法则，总复杂度等于量级最大的那段代码的复杂度

```c++
int cal(int n) {
   int sum_1 = 0;
   int p = 1;
   for (; p < 100; ++p) {
     sum_1 = sum_1 + p;
   }

   int sum_2 = 0;
   int q = 1;
   for (; q < n; ++q) {
     sum_2 = sum_2 + q;
   }
 
   int sum_3 = 0;
   int i = 1;
   int j = 1;
   for (; i <= n; ++i) {
     j = 1; 
     for (; j <= n; ++j) {
       sum_3 = sum_3 +  i * j;
     }
   }
 
   return sum_1 + sum_2 + sum_3;
 }
```

sum_1与规模无关，sum_2为O(n)，sum_3为O(n^2)，因此为O(n^2)。

如果 T1(n)=O(f(n))，T2(n)=O(g(n))；

那么T(n)=T1(n)+T2(n)=max(O(f(n))，O(g(n))) =O(max(f(n), g(n))).

- 乘法法则，嵌套代码复杂度等于嵌套内外代码复杂度的乘积

这个好理解，略。

#### 2.2.3 常见时间复杂度案例分析

![](/Users/yangzanjie/code/study/数据结构和算法/复杂度量级.jpg)

多项式量级

非多项式量级：只有俩，O(2^n)和O(n!)

- O(1)

  一般代码，只要不存在循环、递归语句，即使有成千上万行，时间复杂度都是O(1)。

- O(log n)、O(n log n)

  对数阶复杂度。

  ```c++
   i=1;
   while (i <= n)  {
     i = i * 2;
   }
  ```

  变量i值从1开始取，每循环一次乘以2。当大于n时，循环结束，变量i的取值是一个等比数列。一个个列出来，就是2^0、2^1、2^2、2^3、、、2^k、、、、2^x  =  n。求解x=log2n，因此复杂度为O(log2n)。

  变化下

  ```c++
   i=1;
   while (i <= n)  {
     i = i * 3;
   }
  ```

  时间复杂度为O(log3n)。

  因为对数间可以相互转换，log3n=log32 ·log2n，因此log3n=log32 · log2n，log32为常量，基于前面的理论O(Cf(n)) = O(f(n))，可以忽略系数，因次此最终为O(log2n)。

  至于nlogn，即对logn的算法循环执行n遍。

- O(m+n)、O(m*n)

  代码的复杂度由两个数据的规模决定。

  ```c++
  int cal(int m, int n) {
    int sum_1 = 0;
    int i = 1;
    for (; i < m; ++i) {
      sum_1 = sum_1 + i;
    }
  
    int sum_2 = 0;
    int j = 1;
    for (; j < n; ++j) {
      sum_2 = sum_2 + j;
    }
  
    return sum_1 + sum_2;
  }
  ```

  m和n是表示两个数据规模，因为无法事先评估m和n的量级大小，因此不能简单的用加法法则，忽略掉其中一个，所以代码复杂度就是O(m+n)。

  针对这种情况，加法法则变为，T1(m) + T2(n) = O(f(m) + g(n))；

  但是，乘法法则依然有效，T1(m)*T2(n) = O(f(m) * f(n))。

#### 2.2.4 空间复杂度分析

渐进空间复杂度，表示算法的存储空间和数据规模之间的关系。

```c++
void print(int n) {
  int i = 0;
  int[] a = new int[n];
  for (i; i <n; ++i) {
    a[i] = i * i;
  }

  for (i = n-1; i >= 0; --i) {
    print out a[i]
  }
}
```

在第2行申请了一个空间存储变量i，常量阶，跟n没有关系，不考虑。

在第3行申请了一个大小为n的int类型数组，除此之外，没有别的了，因此空间复杂度O(n)。

#### 2.2.5 小结

常见复杂度，从低到高：O(1)、O(logn)、O(n)、O(nlogn)、O(n^2)。

![](/Users/yangzanjie/code/study/数据结构和算法/常见复杂度.jpg)

#### 2.2.6 Think

- 复杂度分析，提供了一个很好的理论分析方法，无关于宿主机平台，提供了对效率的一个大致的认识。
- 针对不同的宿主机平台，不同的数据集大小，同时需要进行性能测试。
- 需要具有时间和空间分析的思维，为特定应用场景选用适合的算法。

------

## 3 复杂度分析二

最好情况时间复杂度

最坏情况时间复杂度

平均情况时间复杂度

均摊时间复杂度

------

## 4 数组

数组Array：一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。

线性表：数组，链表，队列，栈。

非线性表：二叉树、堆、图等。

数组的“杀手锏”特性：随机访问。

随之而来的代价：删除、插入数据，为保证连续性，需要做大量的数据搬移工作。

针对代价的优化：

- 插入时优化，数组存储没有规律时可用。

- 删除时优化，标记清楚。

  <u>JVM标记清楚算法</u>：大多数主流虚拟机采用可达性分析算法来判断对象是否存活，在标记阶段，会遍历所有GC ROOTS，将所有GC ROOTS可达的对象标记为存活。只有当标记工作完成后，清理工作才会开始。

  <u>不足</u>：

  ​			1、效率问题。标记和清理效率都不高。

  ​			2、空间问题。会产生不连续的内存空间碎片。

数组的访问越界问题。

容器、数组。

数组为何要从0开始：从数组的内存模型看，“下标”最确切的定义是“偏移”，从0开始数组的内存计算公式比从1开始的公式，少一次减法指令，效率更高（基础数据结构，效率优化要做到极致）。

栈：函数体内的局部变量存在栈上，连续压栈，向下增长。

------

## 5 链表

### 5.1 base

经典链表应用场景：LRU缓存淘汰算法。

缓存：提高数据读取性能的技术。如CPU缓存、数据库缓存、浏览器缓存等等。

缓存空间有限，常见缓存淘汰策略：先进先出FIFO、最少使用策略Least Frequency Used--LFU、最近最少使用策略Least Recently Used—LFU。

<u>常用的链表结构</u>

​	单链表

![](/Users/yangzanjie/code/study/数据结构和算法/单链表.jpg)

​	循环链表

![](/Users/yangzanjie/code/study/数据结构和算法/循环链表.jpg)

​	双向链表

![](/Users/yangzanjie/code/study/数据结构和算法/双向链表.jpg)

双向循环链表

![](/Users/yangzanjie/code/study/数据结构和算法/双向循环链表.jpg)

删除操作

- 删除节点中“值等于某个给定值”的结点。

  复杂度O(n)

- 删除给定指针指向的结点。

  单链表O(n)，双向链表O(n)

设计思想，空间换时间。

<u>链表数组性能</u>

![](/Users/yangzanjie/code/study/数据结构和算法/链表数组性能.jpg)

思考：何时使用链表or数组？

数组，简单易用，实现上使用连续的内存空间，可以借助CPU缓存机制，访问效率更高，链表非连续存储，对CPU缓存不友好。

数组，缺点是大小固定，一经声明就要占用整块连续内存空间，如果声明数组过大，可能没有足够的连续内存空间分配，导致内存不足oom。

此外，数组不支持动态扩容，扩容时的数据拷贝十分耗时，而链表天然支持，本身大小并没有限制。

对内存使用苛刻：使用数组，链表会使存储消耗翻倍，对链表频繁的增删，导致内存频繁的申请和释放，容易造成内存碎片。如果是Java语言，会导致频繁的GC。

相比之下，链表更适合插入删除操作频繁的场景，当然实际使用的话，针对实际情况权衡。

### 5.2 如何写好链表

- 技巧一：理解指针或引用的含义

- 技巧二：警惕指针丢失和内存泄漏

- 技巧三：<u>利用哨兵简化实现难度</u>

  针对链表的插入、删除操作，需要对第一个和最后一个结点的情况进行特殊处理。

  带头链表、不带头链表。

  举例：数组，取值为key的下标。

- 技巧四：重点留意边界条件处理

  常用的：

  ​	如果链表为空，ok？

  ​	如果链表只包含一个结点，ok？

  ​	如果链表只包含两个结点，ok？

  ​	逻辑在处理头结点和尾结点时，ok？

  ​	。。。

- 技巧五：举例画图，辅助思考

- 技巧六：多写多练



思考：哨兵简化代码，有什么场景？？？



实现之前，思考时间不要太长，先用能想到的暴力解法试试，此外如果一定时间内，想不出来，google一下。



练习题，LeetCode：206、141、21、19、876

------

## 6 栈



从操作特性上看，栈是一种“操作受限”的线性表，只允许在一端插入和删除数据。

数组实现的栈，顺序栈。

链表实现的栈，链式栈。

时间、空间复杂度：O(1)。

<u>支持动态扩容的顺序栈</u>（参考动态扩容数组的实现），入栈、出栈的时间复杂度分析，最好、最坏时间复杂度，均摊时间复杂度。

<u>栈的应用</u>：

- 函数调用中的应用。
- 表达式求值中的应用：操作数栈，运算符栈。。。

- 在括号匹配中的应用。

  

内存中的“堆栈"和数据中的堆栈：

- 内存，在逻辑上分为三部分，代码区、静态数据区和动态数据区，动态数据区又分为栈区和堆区：

  <u>代码区</u>：存储方法体的二进制代码。高级调度（作业调度）、中级调度（内存调度）、低级调度（进程调度）控制代码区执行代码的切换。

  <u>静态数据区</u>：存储全局变量、静态变量、常量包括final修饰的常量和String常量。系统自动分配和回收。

  <u>栈区</u>：存储运行方法的形参、局部变量、返回值。由系统自动分配和回收。

  <u>堆区</u>：new一个对象的引用或地址存储在栈区，指向该对象存储在堆区中的真实数据。



为什么函数调用要用”栈“来保存临时变量？用其他数据结构不行吗？

- 不一定非要用栈来保存临时变量，只不过如果这个函数的调用符合后进先出的特性，用栈这种数据结构来实现，是最顺理成章的选择。

  从调用函数进入被调用函数，变化的是作用域。从根本上，只要保证每次进入一个新函数，都是一个新的作用域即可。而为了实现这个，用栈很方便。在进入一个新函数时，分配一段栈空间给函数的变量，在函数结束的时候，将栈顶复位，就可以回到调用函数的作用域内。



建议LeetCode: 20,155,232,844,224,682,496.

------



## 7 队列Queue

### base

![](/Users/yangzanjie/code/study/数据结构和算法/队列和栈.jpg)

队列，和栈一样，一种<u>操作受限的线性表数据结构</u>。

<u>**最大特点：先进先出。**</u>

应用广泛：例如循环队列、阻塞队列、并发队列；在很多偏底层系统、框架、中间件的开发中，起着关键性作用，例如高性能队列Disruptor、Linux环形缓存，用了循环并发队列；Java concurrent并发包利用ArrayBlockingQueue来实现公平锁等。

顺序队列：数组实现的。

链式队列：链表实现的。



<u>循环队列</u>：关键是确定好队空和队满的条件。



<u>阻塞队列</u>：队列为空时，从队头取数据会被阻塞，直到有了数据才会返回；队列满时，插入数据的操作会被阻塞，直到队列有空闲位置再插入数据。基于阻塞队列，实现“生产者-消费者模型”。

![](/Users/yangzanjie/code/study/数据结构和算法/阻塞队列.jpg)

提高效率，设置多个“消费者”。

![](/Users/yangzanjie/code/study/数据结构和算法/阻塞队列-多消费者.jpg)

<u>并发队列</u>：线程安全。简单的实现方法，直接在enqueue()、dequeue()方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或读操作。

基于数组的循环数组，利用CAS原子操作，可以实现非常高效的并发队列。（因此循环队列比之链式队列应用更为广泛）



<u>线程池无空闲线程时，请求线程资源时，线程该如何处理？各种策略如何实现？</u>

- 非阻塞处理方式，直接拒绝。

- 阻塞处理方式，将请求排队，等有空闲线程时，取出排队请求继续处理。

  <u>如何存储排队请求？</u>

  希望公平处理排队请求，先进者，先服务，因此Queue适合存储排队请求。

  <u>Queue有基于数组的和基于队列的，有何区别？</u>

  基于队列的，实现一个支持无限排队的无界队列，可能会导致队列过长，请求时间过长，因此针对响应时间敏感的系统，基于链表实现的。。。。不合适。

  基于数组的，队列大小有限，请求超过队列大小时，请求会被拒绝，因此，针对响应时间敏感的系统，比较适合，设置队列大小很有讲究，设置的不合适会导致无法充分利用系统资源、发挥最大性能。



<u>应用</u>：队列可以应用在任何有限资源池中，例如数据库连接池等。



<u>思考</u>：

1. 除了线程池、数据库连接池之外，还有哪些类似的池结构或场景中会用到队列的排队请求呢？

   Ansewr：

   分布式应用中的消息队列，比如kafka也是一种队列；

   

2. 关于如何实现无锁并发队列，这个怎么看？

   Answer：

   考虑使用cas实现无锁队列：入队前获取tail位置，入队时，比较tail位置，是否有发生变化，否，则允许，否则失败。出队则获取head位置，进行cas。



😂😂😂😂吃多了拉，就是队列，吃多了吐，就是栈。

------



## 8 递归

### base



<u>**递归需要满足的三个条件**</u>：

- 一个问题可以分解成几个子问题的解：

  子问题，就是数据规模更小的解。

- 这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样
- 存在递归终止条件



<u>**如何写递归代码？**</u>

关键：写出递推公式，找到终止条件。

![](/Users/yangzanjie/code/study/数据结构和算法/写递归代码的关键.jpg)

**😭😭😭思维误区：只要遇到递归，就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。**



<u>**递归代码要警惕堆栈溢出**</u>

函数使用栈来保存临时变量，每调用一个函数，都会将临时变量封装为栈桢压入内存，等函数执行完才返回，才出栈。而系统栈或者虚拟机栈空间一般都不大，如果递归求解的数据规模很大，调用层次很深，一直压入栈，就会有堆栈溢出的风险。

<u>如何避免？</u>

- 限制递归调用的最大深度
- 看使用情况，是否适合用递归



<u>**警惕重复计算**</u>

![递归重复计算](/Users/yangzanjie/code/study/数据结构和算法/递归重复计算.jpg)

如计算f(5)，需要计算f(4)和f(3)，而计算f(4)需要计算f(2)，在这里需要避免重复计算f(3)。

为了避免重复计算，可以通过 一个数据结构（比如散列表）来保存已经求解过的f(k)。当计算到f(k)时，可以。。。。



<u>**递归有利有弊**</u>

利：表达能力强，代码简洁。

弊：递归代码，需要考虑时间成本（调用函数输了较大时，会积聚成一个客观的时间成本）和空间成本（递归调用，栈。。。），空间复杂度高、有堆栈溢出的风险、存在重复计算、过多的函数调用耗时多等问题。



<u>**如何将递归代码改写为非递归代码**</u>？

。。。



<u>**如何找到“最终推荐人”问题**</u>

![最终推荐人](/Users/yangzanjie/code/study/数据结构和算法/最终推荐人.jpg)

```java
long findRootReferrerId(long actorId) {
  Long referrerId = select referrer_id from [table] where actor_id = actorId;
  if (referrerId == null) return actorId;
  return findRootReferrerId(referrerId);
}

```

上述代码用了递归

但是实际不能在项目中使用：

- 存在堆栈溢出风险
- 如果存在脏数据，会产生无限递归问题

解决方法：

- 限制递归深度
- 检测环的存在，例如A-B-C-A



<u>**好的递归代码调试方法**</u>：

打印日志发现，递归值；

结合条件断点进行调试；

------



## 9 排序

![三类排序算法](/Users/yangzanjie/code/study/数据结构和算法/三类排序算法.jpg)



### 9.1 base & 3个O(n^2)的排序算法



<u>**如何分析一个排序算法**</u>

- 最好情况、最坏情况、平均情况时间复杂度

- 时间复杂度的系数、场数、低阶

  在实际开发中，数据规模可能是10、100、1000这样的规模很小的数据，需要考虑系数。

- 比较次数和交换（或移动）次数

  基于比较的排序算法的执行过程，涉及比较和元素交换移动操作，考虑执行效率时，需要将这个也考虑进去。



**<u>排序算法的内存消耗</u>**

**原地排序**sorted in place，特指空间复杂度是O(1)的排序算法。



**<u>排序算法的稳定性</u>**

比如有一组数据2，9，3，4，8，3，

排序后，2，3，3，4，8，9

若排序后两个3的顺序没有发生改变，则为稳定的排序算法；

若发生变化，则为不稳定的排序算法。

例如电商订单根据下单时间、金额排序。。。



<u>**冒泡排序**</u>

- 只涉及相邻数据的交换操作，只需要常量级的临时空间，空间复杂度是O(1)，是一个原地排序算法。

- 相邻元素大小相等时，不做排序。因此稳定

- 时间复杂度

  最好 O(n)

  最坏 O(n^2)

  平均：引入有序度和逆序度。。。略。。。O(n^2)

  **逆序度=n*(n-1)/2-初识有序度**



<u>**插入排序**</u>

思想：找到数据该插入的位置。

已排序区间和未排序区间。

- 不需要额外的存储空间，原地排序

- 稳定

- 时间复杂度

  最好O(n)

  最坏O(n^2)

  平均：往数组插入一个数据的平均复杂度是O(n)，因此对于一个数组，执行n次，就是O(n^2)



<u>**选择排序**</u>

- 原地排序
- 不稳，每次都要找到最小的值，并交换位置。



<u>**冒泡排序和插入排序的时间复杂度都是O(n^2)，为何插入排序比冒泡排序更受欢迎？**</u>

两者元素交换的次数都是原始数据的逆序度。

```c++
冒泡排序中数据的交换操作：
if (a[j] > a[j+1]) { // 交换
   int tmp = a[j];
   a[j] = a[j+1];
   a[j+1] = tmp;
   flag = true;
}

插入排序中数据的移动操作：
if (a[j] > value) {
  a[j+1] = a[j];  // 数据移动
} else {
  break;
}

```

冒泡排序的数据交换更为复杂，需要3次赋值，而插入排序需要1次。



![冒泡插入选择排序](/Users/yangzanjie/code/study/数据结构和算法/冒泡插入选择排序.jpg)



插入排序的优化，<u>**希尔排序**</u>。



<u>**思考**</u>

若数据存储于链表，三种排序算法还能工作吗？

相应的时间、空间复杂度？

![排序1思考答案](/Users/yangzanjie/code/study/数据结构和算法/排序1思考答案.jpg)

------

### 9.2 归并排序&快速排序

两种都是O(nlogn)的排序

#### 9.2.1 归并排序 Merge Sort

![归并排序分解图](/Users/yangzanjie/code/study/数据结构和算法/归并排序分解图.jpg)

分治思想，分而治之，将一个大问题分解成小的问题来解决，解决小问题，即可解决大问题。

分治一般用递归来实现。

分治是一种解决问题的处理思想，递归是一种编程技巧。

<u>**按前述递归章节，先写出公式：**</u>

```
递推公式：
merge_sort(p…r) = merge(merge_sort(p…q), merge_sort(q+1…r))

终止条件：
p >= r 不用再继续分解
```

（👍👍👍。。。。牛皮）

<u>**进而写出伪代码：**</u>

```
// 归并排序算法, A 是数组，n 表示数组大小
merge_sort(A, n) {
  merge_sort_c(A, 0, n-1)
}

// 递归调用函数
merge_sort_c(A, p, r) {
  // 递归终止条件
  if p >= r  then return

  // 取 p 到 r 之间的中间位置 q
  q = (p+r) / 2
  // 分治递归
  merge_sort_c(A, p, q)
  merge_sort_c(A, q+1, r)
  // 将 A[p...q] 和 A[q+1...r] 合并为 A[p...r]
  merge(A[p...r], A[p...q], A[q+1...r])
}
```

<u>**merge的伪代码**</u>

```
merge(A[p...r], A[p...q], A[q+1...r]) {
  var i := p，j := q+1，k := 0 // 初始化变量 i, j, k
  var tmp := new array[0...r-p] // 申请一个大小跟 A[p...r] 一样的临时数组
  while i<=q AND j<=r do {
    if A[i] <= A[j] {
      tmp[k++] = A[i++] // i++ 等于 i:=i+1
    } else {
      tmp[k++] = A[j++]
    }
  }
  
  // 判断哪个子数组中有剩余的数据
  var start := i，end := q
  if j<=r then start := j, end:=r
  
  // 将剩余的数据拷贝到临时数组 tmp
  while start <= end do {
    tmp[k++] = A[start++]
  }
  
  // 将 tmp 中的数组拷贝回 A[p...r]
  for i:=0 to r-p do {
    A[p+i] = tmp[i]
  }
}
```

（牛皮啊😂😂😂）



<u>**思考😭😭😭😭**</u>

借用上述章节提到过的“哨兵”编程技巧，merge的代码就会很简洁，do it。



<u>**性能分析**</u>

- 稳定性

  稳定性，看merge的处理，若A[p...q], A[q+1...r]中有相同的元素，可以先放A[p...q]中的值，那么归并排序是稳定的。

- 时间复杂度

  涉及递归，分析稍微有点复杂😇。略了。[https://time.geekbang.org/column/article/41913](极客时间-数据结构与算法之美-12排序下)

  十分稳定，在任何情况下，最好、最坏、平均都是O(nlogn)

- 空间复杂度

  看起来非常优秀，快速排序最坏情况时间复杂度O(n^2)，没这个好，但是快排应用更为广泛。

  <u>**”致命“弱点**</u>：不是原地排序算法，在合并两数组时，需要借助额外的存储空间。（<u>**注：**</u>不能用分析时间的思路，来分析空间，因为在合并完成后，申请开辟的空间会被释放掉，在任意时刻，CPU只有一个函数在运行，只会有一个临时的内存空间在使用，该空间不会超过n个数据的大小，所以空间复杂度时O(n)。）



#### 9.2.2 快速排序QuckSort

![快速排序原理](/Users/yangzanjie/code/study/数据结构和算法/快速排序原理.jpg)

分治思想：。。。。直到区间缩小为1。



<u>**递推公式：**</u>

```
递推公式：
quick_sort(p…r) = quick_sort(p…q-1) + quick_sort(q+1, r)

终止条件：
p >= r
```



<u>**递归伪代码：**</u>

```
// 快速排序，A 是数组，n 表示数组的大小
quick_sort(A, n) {
  quick_sort_c(A, 0, n-1)
}
// 快速排序递归函数，p,r 为下标
quick_sort_c(A, p, r) {
  if p >= r then return
  
  q = partition(A, p, r) // 获取分区点
  quick_sort_c(A, p, q-1)
  quick_sort_c(A, q+1, r)
}
```



**<u>分区函数伪代码（为保证是原地排序）</u>**：

```
partition(A, p, r) {
  pivot := A[r]
  i := p
  for j := p to r-1 do {
    if A[j] < pivot {
      swap A[i] with A[j]
      i := i+1
    }
  }
  swap A[i] with A[r]
  return i
```

![快排分区函数图解](/Users/yangzanjie/code/study/数据结构和算法/快排分区函数图解.jpg)

（涉及交换操作，不稳定，例如序列6，8，7，6，3，5，第一次分区后，6的顺序就换了。）



<u>**归并&快排的区别**</u>

![归并&快排的区别](/Users/yangzanjie/code/study/数据结构和算法/归并&快排的区别.jpg)

归并：由下到上，先处理子问题，然后再合并。

快排：由上到下，先分区，再处理子问题。



<u>**快排性能分析**</u>：

- 原地

- 不稳定

- 时间复杂度

  [https://time.geekbang.org/column/article/41913](极客时间-数据结构与算法之美-12排序下)

  如果每次分区，正好等分数据，那么和归并排序是一样的O(nlogn)；

  若极端的看，每次pivot选择最后一个元素，退化为O(n^2)。

  递归树求解，后续将。



<u>**思考**</u>：

如何在O(n)的时间复杂度内查找一个无序数组中的第K大元素？

<u>利用分区的思想</u>

------



## 10 线性排序 Linear Orders

三种时间复杂度O(n)的排序算法：桶排序、计数排序、基数排序。

因为这些算法是非基于比较的排序算法，都不涉及元素之间的比较操作。

### 10.1 桶排序 Bucket Sort

<u>**核心思想**</u>：将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。桶内拍完序之后，再把桶里的数据按照顺序依次取出，组成的序列就是有序的。

<u>**限制**</u>：首先数据要容易划分成m个桶，然后，桶之间要有天然的大小顺序，其次，各个桶之间的分布是比较均匀的。（如果数据都被划分到一个桶里，那就退化为O(nlogn)了。）

<u>**应用**</u>：比较适合在<u>**外部排序**</u>中，所谓外部排序就是，数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中。



### 10.2 计数排序 Counting Sort

（桶排序的一种特殊情况。）

当要排序的n个数据，所处的范围并不大的时候，例如最大值是k，那么就可以将数据划分成k个桶。每个桶内的数据都是相同的，省掉了桶内排序的时间。

利用另一个数组来计数。。。略。。。

限制：计数排序只能用在数据范围不大的场景中，如果数据范围要比排序的数据n大很多，就不适合用计数排序了。而且，计数排序只能给非负整数排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数。



### 10.3 基数排序 Radix Sort

一个排序问题，对10万个手机号码排序。手机号码11位，范围大。

规律：比较号码a、b，如果号码前几位中，a比b大了，那么后几位就不用看了。

实现思路：先按最后一位对手机号码进行排序，然后按倒数第二位，依次类推。

这里按照每位来排序的算法，要求是稳定的，否则无法实现。

这里的每位排序算法，可以用 桶排序或者计数排序，。。。略。

对于位数不一致的数据，可以认为“补齐”到相同长度。

<u>**限制**</u>：对数据有要求，需要可以分割出独立的“位”来比较，而且位之间有递进的关系。除此之a，每一位的数据范围不能太大，要可以用线性算法来排序。

------



## 11 排序优化

<u>**如何实现一个通用的、高性能的排序函数？**</u>



![排序算法回顾](/Users/yangzanjie/code/study/数据结构和算法/排序算法回顾.jpg)



线性排序，对数据有要求，因此不适合。

归并排序和快速排序都是O(nlogn)，但是归并排序不是原地排序，因此也不考虑。

快速排序，最坏情况下，会退化为O(n^2)，因此要对此进行优化。

优化点：分区算法。

- 三数取中法
- 随机法
- 。。。。

------



## 12 二分查找 Binary Search

### 12.1 base

二分查找针对的是一个有序的数据集合，。。。

时间复杂度O(logn)

实现：

循环实现，递归实现。

<u>**局限性**</u>：

- 依赖顺序表结构，简单说就是数组。

  链表的话，随机访问复杂度O(n)

- 针对有序数据。

  若无序，先排序。

  若针对一组静态数据，没有频繁的插入、删除，则可以一次排序，多次二分查找。

  但是，若是数据集合有频繁的插入和删除操作，要保证每次操作之后有序，则在每次二分查找之前，进行排序，维护成本很高。

  因此适用于插入、删除操作不频繁，一次排序，多次查找的场景中。针对动态数据，二分查找不适用。

- 数据量太小，不适合二分查找。

  数据量小时，没必要，顺序遍历足够了。

  此外，若是数据间的比较操作非常耗时，不管数据量大小，都推荐使用二分查找，尽可能减少比较次数。

- 数据量太大，也不适合二分查找。

  二分查找，底层依赖数组这种数据结构，而数组为了支持随机访问的特性，要求内存空间<u>**连续**</u>，对内存的要求比较苛刻。



notice：二分查找的边界问题。



思考：

1、如何在1000万个整数块中快速查找某个整数？

2、如何编程实现“求一个数的平方根”，要求精确到小数点后6位。

3、链表存储的话，二分查找的时间复杂度。



### 12.2 二分查找的变形

<u>**如何快速定位IP对应的省份地址？**</u>

二分查找的变形，查找最后一个小于等于给定值

![二分查找的变形](/Users/yangzanjie/code/study/数据结构和算法/二分查找的变形.jpg)



<u>**notice：对于做工程开发的来说，代码易读懂、没bug，更为重要。**</u>我也这个认为😂😂😂



<u>**二分查找易出bug的地方**</u>：终止条件、区间上下界更新方法、返回值选择。



思考：如果有序数组是一个循环有序数组，例如4,5,6,1,2,3。针对这种情况，如何实现一个求值等于给定值的二分查找算法？

![有序循环数组的二分查询](/Users/yangzanjie/code/study/数据结构和算法/有序循环数组的二分查询.jpg)



------



## 13 跳表 Skip List

<u>**问：为什么Redis一定要用跳表来实现？**</u>



一种动态数据结构（对链表稍加改造）。

可以支持快速的插入、删除、查找操作，不复杂，甚至可以替代红黑树（Red-black tree）。

<u>**跳表：链表加多级索引的结构。**</u>

设计思路：空间换时间。

时间复杂度：O(logn)。

空间复杂度：O(n)。

<u>**notice**</u>：实际开发中，原始链表中存储的很有可能是很大的对象，而索引结点只需要存储关键值和几个指针，并不需要存储对象，因此当对象比索引结点大很多时，索引占用的额外空间就可以忽略了。



<u>**高效的动态插入和删除**</u>

时间复杂度：O(logn)。



<u>**跳表索引动态更新**</u>

如果不更新索引，可能出现两个索引结点之间数据非常多的情况，极端情况下，会退化成单链表。

插入时，选择同事将数据插入到部分索引层中。

通过随机函数决定插入到第几级索引中。

随机函数的选择很有讲究，从概率上讲，需要保证跳表的索引大小和数据大小平衡性，不至于性能过渡退化。



<u>**思考**</u>：如果每三个或者五个结点作为上级索引，对应的在跳表中查找数据的时间复杂度是多少？

------



## 14 散列表 Hash Table

### 14.1 

<u>**问：Word文档中的单词拼写检查功能是如何实现的？**</u>



散列思想

散列表用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来。

![散列表](/Users/yangzanjie/code/study/数据结构和算法/散列表.jpg)

散列函数，又称为哈希算法。

散列冲突解决方法：

- <u>**开放寻址法**</u> 

  线性探测

  二次探测

  双重散列

  <u>**notice**</u>：不管采用哪种探测方法，当散列表中空闲位置不多的时候，散列冲突的概率就会大大提高。为了尽可能保证散列表的操作效率，一般情况下，会尽可能保证散列表中有一定比例的空闲槽位。

  用装载因子load fator表示空位的多少。

  散列表的装载因子=填入表中的元素个数/散列表中的长度

- <u>**链表法**</u>

  更加常用，相比开放寻址，也简单很多。

  ![散列表-链表法](/Users/yangzanjie/code/study/数据结构和算法/散列表-链表法.jpg)



核心问题：<u>**散列函数设计**</u>和<u>**散列冲突解决**</u>。



<u>**思考**</u>：

1、假设我们有10万条URL访问日志，如何按照访问次数给URL排序？

2、有两个字符串数组，每个数组大约有10万条字符串，如何快速找出两个数组中的相同字符串？



### 14.2

<u>**问：如何打造一个工业级水平的散列表？**</u>

来避免散列冲突下，散列表性能急剧下降，并且抵抗散列碰撞攻击。



<u>**如何设计散列函数？**</u>

- 不能太复杂。过于复杂，会消耗很多计算时间。
- 散列函数生成的值要尽可能随机并且均匀分布。这样才能避免或者最小化散列冲突。
- 实际工作中，还要综合考虑各种因素，例如关键字长度、特点、分布、散列表大小等。

一般有，“数据分析法”，直接寻址法，平方取中法，折叠法，随机数法等。



<u>**装载因子过大？**</u>

静态数据集合，好处理，数据已知，可设计出好的散列函数。

动态数据集合，平凡变动，无法预估要加入的数据个数，随着数据慢慢加入，装载因子慢慢变大，如何处理？

<u>**动态扩容**</u>

重新申请一个更大的散列表。复杂。

对于支持动态扩容的散列表，插入操作的时间复杂度是多少？

最好时间复杂度O(1)。

最坏，启动扩容，重新申请内存空间，重新计算哈希位置，O(n)。

摊还分析法，时间复杂度接近最好情况，O(1)。

<u>**动态缩容**</u>

随着删除的数据越来越多，空闲空间越来越多。

装载因子阈值的选择要权衡时间、空间复杂度。



<u>**如何避免低效的扩容？**</u>

一次性扩容耗时过多。

设计思想：将扩容操作穿插在插入操作中，分批次完成。

这期间的查询操作，为了兼容新、老散列表中的数据，先从新的查找，再从老的散列表中查找。

这种实现方式，在任何情况下，插入一个数据的时间复杂度都是O(1)。



<u>**如何选择冲突解决方法？**</u>

开放寻址法和链表法，都很常用。

例如Java中的LinkedHashMap就采用了链表法解决冲突，ThreadLocalMap通过线性探测开放寻址法解决冲突。

<u>**优劣分析**</u>

开放寻址法

- 优点
  1. 无链表，因此能有效利用cpu缓存加快查询速度。
  2. 序列化简单。链表法序列化比较难。
- 缺点
  1. 删除数据比较麻烦，需要特殊标记已删除的数据。
  2. 相对于链表法，开放寻址法所有的数据都存储于一个数组中，冲突的代价更高。因此，装载因子的上限不能太大，比较浪费内存空间。

链表法

- 优点
  1. 对内存的利用率比开放寻址法高，因为链表结点可以在需要的时候创建，并不需要像开放寻址法一样提前申请好。
  2. 对大装载因子的容忍度更高，开放寻址法只能适用于装载因子小于1的情况，接近1时，会有大量的冲突，性能下降剧烈 。而对于链表法来说，只要散列函数的值随机均匀，装载因子即便大于1，也只是链表长度变长，查找效率下降比较少。
- 缺点
  1. 链表需要存指针，因此对于小对象的存储来说，比较消耗内存，有可能让内存翻倍。此外链表的零散分布，对于cpu缓存也是不友好的，对执行效率有一定影响。当然对大对象，存储可以忽略。

对链表法改进，将链表改造为其他更高效的<u>**动态数据结构**</u>，比如跳表、红黑树，这样即使出现散列冲突，极端情况下，所有的数据都散列到一个桶内，退化的散列表的查询时间也只是O(logn)，即动态数据结构的查询时间，可以避免散列碰撞攻击。

<u>**总结：**</u>

基于链表的散列冲突方法，适合存储大对象、大数据量的散列表，而且相比于开放寻址法，更为灵活，支持更多的优化策略，比如用红黄树替代链表。

对于小规模、装载因子不高散列表，比较适用开放寻址法。



<u>**工业级散列表举例分析**</u>

Java中的HashMap分析

1. 初始大小
2. 装载因子和动态扩容
3. 散列冲突的解决方法
4. 散列函数（哈希函数）



回答问题：

何为一个工业级的散列表？应该有哪些特性？

- 支持快速的查询、删除、插入操作
- 内存占用合理
- 性能稳定，极端情况下，散列表性能不会退化到无法接受

如何实现？

- 设计一个合理的散列函数
- 定义装载因子阈值（合理），设计动态扩容策略（甚至缩容）
- 选择合理的散列冲突解决方法



<u>**思考：**</u>

在熟悉的编程语言中，哪些数据类型是基于散列表实现的？散列函数是如何设计的？散列冲突是通过哪种方法解决的？是否支持动态扩容？



### 14.3

<u>**问：为何散列表经常和链表一起使用？**</u>



<u>**LRU算法介绍**</u>

当要缓存某个数据时，先在链表中查找这个数据，若没有找到，直接在链表尾部插入这个数据，此时若缓存已满，还需将链表头部的数据删除；如果找到了，则将它移动到链表的尾部。



<u>**缓存 cache 特性**</u>

1. 插入一个数据
2. 删除一个数据
3. 查询一个数据

![散列表-双向循环链表组合](/Users/yangzanjie/code/study/数据结构和算法/散列表-双向循环链表组合.jpg)

<u>**分析实现略**</u>



<u>**Redis有序集合**</u>

key（键值）----score（分值）

通过key、score分别查询



Java中的LinkedHashMap

是通过双向链表和散列表这两种数据结构组合实现的。



<u>**思考**</u>

1、前述散列表和链表结合使用的例子里，用的都是双向链表，改成单向链表，是否还能正常工作？为什么？

2、假设猎聘网有10万名猎头，每个猎头都可以通过做任务（比如发布职位）来积累积分，然后通过积分来下载简历。假设你是猎聘网的一名工程师，如何在内存中存储这10万个猎头的ID和积分信息，让他能够支持这样的几个操作：

- 根据猎头的ID快速查找、删除、更新、这个猎头的积分信息；
- 查找积分在某个区间的猎头ID列表；
- 查找按照积分从小到大排名在第X位到第Y位之间的猎头ID列表

![散列表和链表组合思考](/Users/yangzanjie/code/study/数据结构和算法/散列表和链表组合思考.jpg)

------



## 15 哈希算法 Hash Algorithm

### 15.1

<u>**什么是哈希算法**</u>

将任意长度的二进制串映射为固定长度的二进制串，这个映射规则就是哈希算法，映射后的二进制串就是哈希值。

哈希算法的要求：

- 从哈希值不能反向推导出元数据。（单向哈希算法）
- 对输入数据非常敏感，哪怕原始数据只修改了一个bit，最后得到的哈希值也大不相同。
- 散列冲突的概率要很小，对于不同的原始数据，哈希值想听的概率非常小。
- 哈希算法的执行效率尽量高效，针对较长的文本，也能快速地计算出哈希值。



<u>**哈希算法的应用**</u>

1. <u>**安全加密**</u>：最常用的有MD5-消息摘要算法，SHA-安全散列法，其他的，DES-数据加密标准，AES-高级加密标准。
2. <u>**唯一标识**</u>：对大数据做信息摘要，通过一个较短的二进制编码来标识很大的数据。
3. <u>**数据校验**</u>
4. <u>**散列函数**</u>



字典攻击

防御字典攻击：引入盐salt，与用户的密码组合。



<u>**思考：区块链是一个很多的领域，其底层的实现原理并不复杂，哈希算法是其非常重要的一个理论基础。区块链使用的是哪一种哈希算法，是为了解决什么问题而使用的？**</u>

<u>**Answer**</u>：

区块链是一块块区块组成，每个区块分为两个部分：区块头，和区块体。

区块头保存着自己区块体和上一个区块头的哈希值。

因为这种链式关系和哈希值的唯一性，只要区块链上任意一个区块被修改过，后面所有区块保存的哈希值就不对了。

区块链使用的是SHA256哈希算法，计算哈希值非常耗时，如果要改一个区块，就必须重新计算该区块后面所有区块的哈希值，短时间内几乎不可能做到。



### 15.2

<u>**在分布式系统中的应用**</u>

1. <u>**负载均衡**</u>

   负载均衡算法有很多，比如轮询、随机、加权轮询等。

   如何实现会话粘滞(session sticky)的负载均衡算法？即，在同一个客户端上，在一次会话中的所有请求都路由到同一个服务器上。

   最直接的方法，维护一张表（客户端ip或者会话id与服务器编号映射关系的表），弊端：映射表会随客户增多而增大，浪费内存空间；客户端下线、上线，服务器扩容、缩容会导致映射失效，维护映射表的成本会变大。

   借助哈希算法，对客户端ip或者会话id计算哈希值，将取得的哈希值与服务器列表进行取模运算，最终得到的值就是该被路由到的服务器编号。

2. <u>**数据分片**</u>

   - <u>**如何统计“搜索关键词”出现的次数？**</u>

     假如有1T的日志文件，记录了用户的搜索关键词，如何快速统计出每个关键词的搜索次数，该如何做？

     难点一：数据量大，无法放到一台机器的内存。

     难点二：若只用一台机器处理这么巨大的数据，处理时间会很长。

     解决方案：先对数据进行分片，然后采用多台机器处理的方法，提高数据处理速度。

     具体思路：用n台机器并行处理，从搜索记录的日志文件中，依次读出每个搜索关键词，通过哈希函数计算哈希值，然后再跟n取模，最终得到的值，就是应该被分配到的机器编号。

     这样一来，哈希值相同的搜索关键词就被分配到了同一个机器上。即，同一个搜索关键词被分配到同一个机器上。每个计算器分别计算关键词出现的次数，最终合并起来就是最终的结果。

     这就是MapReduce的基本设计思想。😂😂😂👍👍👍

   - <u>**如何快速判断图片是否在图库中？**</u>

     对小数据量的图片，给每个图片取唯一标识（或者信息标识），然后构建散列表。

     然而对于大数据量的图片（例如一亿张图片），在单台机器上构建散列表是行不通的。

     因此同样要对数据进行分片，采用多机处理。

     ![一亿张图片数据分片处理估算](/Users/yangzanjie/code/study/数据结构和算法/一亿张图片数据分片处理估算.jpg)

3. <u>**分布式存储**</u>

   面对海量数据、海量用户。为了提高数据的读取、写入能力，一般都采用分布式的方式来存储数据，例如分布式缓存。

   <u>**如何决定将哪个数据放到哪个机器上？**</u>

   借用数据分片的思想。

   但是随着数据增多，需要扩容。此时取模运算结果会发生变化。因此所有数据需要重新计算哈希值，然后重新搬到正确的机器上。这就相当于，缓存中的数据一下子都失效了。所有的数据请求都会穿透缓存，直接去请求数据库。这样可能发生雪崩效应，压垮数据库。

   因此，需要一种方法，使得新加入一个机器后，不需要做大量的数据搬移。

   *<u>**一致性哈希算法**</u>*

   ![一致性哈希算法](/Users/yangzanjie/code/study/数据结构和算法/一致性哈希算法.jpg)

[](https://zh.wikipedia.org/wiki/%E4%B8%80%E8%87%B4%E5%93%88%E5%B8%8C)

[](https://www.jianshu.com/p/570dc8913c20)



<u>**思考：哈希算法还有很多应用，例如网络协议中的CRC校验、GIT commit id等等，除了这些，还有哪些用到了哈希算法？**</u>

------



## 16 二叉树

### 16.1 树、二叉树

非线性表结构

<u>**问题：二叉树有哪几种存储方式？什么样的二叉树适合用数组来存储？**</u>



树Tree

![树](/Users/yangzanjie/code/study/数据结构和算法/树.jpg)

概念：父节点，子节点，兄弟结点，根节点，叶子结点（叶节点）；高度Height，深度Depth，层Level

![树的高度、深度、层](/Users/yangzanjie/code/study/数据结构和算法/树的高度、深度、层.jpg)

![树的高度、深度、层-例子](/Users/yangzanjie/code/study/数据结构和算法/树的高度、深度、层-例子.jpg)



<u>**二叉树**</u>

每个节点最多有两个“叉”，即两个子节点。

满二叉树。

完全二叉树。



<u>**如何表示（存储）一颗二叉树？**</u>

1. 链式存储法（基于指针或者引用）

   ![二叉树-链式存储法](/Users/yangzanjie/code/study/数据结构和算法/二叉树-链式存储法.jpg)

2. 顺序存储法

   完全二叉树

   ![二叉树-顺序存储法](/Users/yangzanjie/code/study/数据结构和算法/二叉树-顺序存储法-完全二叉树.jpg)

   非完全二叉树

   ![二叉树-顺序存储法-非完全二叉树](/Users/yangzanjie/code/study/数据结构和算法/二叉树-顺序存储法-非完全二叉树.jpg)

   所以，完全二叉树是最节省内存的一种方式。

   （堆其实就是一种完全二叉树，最常用的存储方式就是数组。）



**二叉树的遍历**

如何将所有的节点遍历打印出来？

经典的方法：前序遍历、中序遍历、后序遍历，前、中、后表示节点与它的左右子树节点遍历打印的先后顺序。

![二叉树遍历-前中后序](/Users/yangzanjie/code/study/数据结构和算法/二叉树遍历-前中后序.jpg)

**<u>前中后序遍历就是一个递归的过程。</u>**

```
前序遍历的递推公式：
preOrder(r) = print r->preOrder(r->left)->preOrder(r->right)

中序遍历的递推公式：
inOrder(r) = inOrder(r->left)->print r->inOrder(r->right)

后序遍历的递推公式：
postOrder(r) = postOrder(r->left)->postOrder(r->right)->print r
```

代码实现：

```c++
void preOrder(Node* root) {
  if (root == null) return;
  print root // 此处为伪代码，表示打印 root 节点
  preOrder(root->left);
  preOrder(root->right);
}

void inOrder(Node* root) {
  if (root == null) return;
  inOrder(root->left);
  print root // 此处为伪代码，表示打印 root 节点
  inOrder(root->right);
}

void postOrder(Node* root) {
  if (root == null) return;
  postOrder(root->left);
  postOrder(root->right);
  print root // 此处为伪代码，表示打印 root 节点
}
```

<u>**二叉树遍历的时间复杂度：**</u>

从前面的遍历顺序图看，每个节点最多被访问两次，所以遍历时间复杂度跟节点个数n成正比，二叉树遍历的时间复杂度是O(n)。



数组顺序存储的方式比较适合完全二叉树，其他类型的二叉树比较浪费内存空间。



<u>**思考：**</u>

1. 给定一组数据，比如1，3，5，6，9，10。可以构建出多少种不同的二叉树？
2. 三种遍历方式，前中后序，还有一种遍历方式，按层遍历，如何实现呢？



<u>**卡特兰数**</u>

- 出栈问题
- 二叉树构成问题
- 凸多边形的三角形划分
- 括号匹配，01序列等





### 16.2 二叉查找树

支持动态数据集合的快速插入、删除、查找操作。

<u>**Q:既然有了这么高效的散列表，使用二叉树的地方是不是都可以替换成散列表呢？有没有哪些地方是散列表做不了，必须要用二叉树来做的呢？**</u>



<u>**二叉查找树 Binary Search Tree**</u>      二叉搜索树

最常用的类型。

为了实现快速查找而生，还支持快速插入、删除一个数据。

<u>**结构：在树中的任意一个节点，其左子树中的每个节点的值，都要小于这个节点的值，而右节点的值都要大于这个节点的值。**</u>

![二叉查找树](/Users/yangzanjie/code/study/数据结构和算法/二叉查找树.jpg)

- 查找操作

- 插入操作

- 删除操作（相较于上面两个，复杂点）

  处理三种情况

  1. 删除的节点，没有子节点，直接删除即可。
  2. 删除的节点，只有一个子节点，只要将待删除节点的父节点的指向删除节点的指针指向其子节点。
  3. 删除的节点，有两个子节点。需要找到右节点子树中的最小节点，然后按第二种情况类似的操作。

  另外一种，取巧的方法，单纯将要删除的节点标记为“已删除”，但并不真正从树中将这个节点去掉。虽然比较浪费内存空间，但删除操作变简单了好多。

- 其他操作

  快速查找最大节点和最小节点、前驱节点和后继节点。

<u>**重要特性**</u>

​	中序遍历二叉查找树，可以输出有序的数据序列，时间复杂度是O(n)，非常高效，因此又名二叉排序树。



<u>**支持重复数据的二叉查找树**</u>

两种思路：

1. 通链表和支持动态扩容的数组等数据结构，把相同的值都存储在同一个节点上。
2. 每个节点依然只存储一个数据：
   - 相同的数据按大于这个节点的值处理。
   - 其他处理相同



<u>**时间复杂度分析**</u>

![二叉查找树的不同形态](/Users/yangzanjie/code/study/数据结构和算法/二叉查找树的不同形态.jpg)

最糟糕情况，左右子树极不平衡，退化成链表。

理想情况，树是一棵完全二叉树或满二叉树。

<u>**时间复杂度跟树的高度成正比。**</u>

那么如何求一棵树的高度？

- 等于最大层数减一

- 计算最大层数

  ![计算完全二叉树的最大层数](/Users/yangzanjie/code/study/数据结构和算法/计算完全二叉树的最大层数.jpg)

极度不平衡的二叉查找树，性能会很差。

因此需要构建一种不管怎么删除、插入数据，在任何时候，都能保持任意节点左右子树都比较平衡的二叉查找树。



<u>**回答Q**</u>

散列表的插入、删除、查找操作的时间复杂度可以做到常量级的O(1)，十分高效。而二叉查找树在比较平衡的情况下，插入、删除、查找的时间复杂度才是O(logn)，为何还要用二叉查找树？

1. 散列表中的数据是无序存储的，如果要输出有序的数据，需要进行排序。而对于二叉查找树，只需要中序遍历，可以在O(n)的时间复杂度内，输出有序的数据序列。
2. 散列表扩容耗时多，而遇到散列冲突时，性能不稳定，尽管二叉查找树的性能不稳定，但是在工程中，最常用的平衡二叉树的性能十分稳定，时间复杂度稳定在O(logN)。
3. 笼统的说，散列表的查找等操作的时间复杂度是常量级的，但是因为哈希冲突的存在，这个常量不一定比O(logN)小，所以实际的速度可能不一定比O(logN)快，加上哈希函数的耗时，效率进一步降低，比一定就比平衡二叉树的效率高。
4. 散列表的构造比二叉查找树要复杂，要考虑的东西有很多。比如散列函数的设计，散列冲突解决办法，扩容，缩容等。而二叉查找树只需要考虑一个平衡性的问题，这个问题的解决方案比较固定、成熟。
5. 为了避免过多的散列冲突，散列表的装载因子不能太大，特别是基于开放寻址法解决冲突的散列表，会浪费一定的存储空间。

综合以上几点，实际开发中，需要结合具体的需求来选择使用哪一个。



<u>**思考：如何通过编程，求出一颗给定二叉树的确切高度？**</u>

两种思路

1. 深度优先的递归，当前结点的最大高度等于max(左子树高度，右子树高度)+1；
2. 采用层次遍历的方式。每一层记录。



### 16.3 平衡二叉树查找、红黑树

<u>**Red Black Tree**</u>



<u>**平衡二叉树**</u>

二叉树中的任意一个节点的左右子树的高度相差不能大于1.

![平衡二叉树&非平衡二叉树](/Users/yangzanjie/code/study/数据结构和算法/平衡二叉树&非平衡二叉树.jpg)

<u>**平衡二叉查找树**</u>
既是平衡二叉树，又满足二叉查找树的特点。



AVL树（严格符合上述定义），但很多不严格符合。

初衷：解决普通二叉查找树在频繁的插入、删除等动态更新的情况下，出现时间复杂度退化的情况。

所以“平衡”的意思，是让整棵树看起来比较“对称”、比较“平衡”，让相应的插入、删除、查找等操作的效率高一些。

不必严格符合定义，只要树的高度不必logN大很多即可。



<u>**如何定义一颗“红黑树”？**</u>

Red-Black Tree, R-B Tree。

节点，一类黑色的，一类红色的。

- 根节点是黑色的
- 每个叶子节点都是黑色的空节点（NIL），即，叶子节点不存储数据
- 任何相邻的节点都不能同时为红色，即，红色节点被黑色节点隔开
- 每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点



<u>**Q：为什么工程中都用红黑树这种二叉树？**</u>

- Treap（树堆）、Splay Tree（伸展树）等平衡二叉查找树，它们操作效率都很高，但是无法避免极端情况下，时间复杂度的退化。尽管这种情况出现的概率不大，但是对于单次操作时间非常敏感的场景来说，它们并不适用。
- AVL树是一种高度平衡的二叉树（严格符合定义），查找效率非常高。但是它付出了代价，每次插入、删除操作都要做调整，比较复杂、耗时，所以对于有频繁插入、删除操作的数据集合，使用AVL树的代价有点高。红黑树，近似平衡，在维护平衡的成本上，比AVL低。

因此，红黑树的插入、删除、查找等操作性能都比较稳定。对于工程应用，面对各种异常情况，比较倾向于用红黑树。



红黑树算是最难掌握的一种数据结构。

<u>**学习数据结构和算法的侧重点，要学习它的由来、特性、适用的场景以及能解决的问题。**</u>

![红黑树的侧重](/Users/yangzanjie/code/study/数据结构和算法/红黑树的侧重.jpg)



<u>**思考：动态数据结构支持动态地数据插入、删除、查找操作，除了红黑树，前面还涉及到哪些？对比一下各自的优势、劣势，以及应用场景。**</u>

[](https://time.geekbang.org/column/article/68638)



### 16.4 红黑树实现

<u>**基本思想**</u>

类似魔方，有固定的算法（遇到哪几面是什么样子，对应怎么转几下）

大致过程：<u>**遇到什么样的节点排布，对应怎么去调整**</u>

<u>**重要操作**</u>

- 左旋 rotate left 围绕某个节点的左旋
- 右旋 rotate right 围绕某个节点的右旋 

![红黑树的左右旋操作](/Users/yangzanjie/code/study/数据结构和算法/红黑树的左右旋操作.jpg)



<u>**插入操作的平衡调整**</u>

<u>**删除操作的平衡调整**</u>

。。。

老铁  这太难了

看不动了



### 16.5 递归树

递归树与时间复杂度分析

略

------

## 17 堆和堆排序

### 17.1

<u>**堆 Heap**</u>

- 堆是一个完全二叉树
- 堆中每一个节点的值都必须大于等于（或小于等于）其子树中每个节点的值。

<u>**往堆中插入元素**</u>

堆化：从上到下，从下到上。

<u>**删除堆顶元素**</u>

最后一个节点放到堆顶，然后堆化。



<u>**如何基于堆实现排序？**</u>

1. 建堆

   将数组原地建堆。

   第一种，插入，从前往后处理。

   第二种，从后往前处理数组。

   时间复杂度O(n)。

2. 排序

时间复杂度：建堆O(n)，<u>**排序O(nlogn)(这里其实没明白)**</u>，因此最后为O(nlogn)。

存在堆顶和末尾节点交换，因此不稳定。



<u>**Q：堆排序时间复杂度和快速排序一样，都是O(nlogn)，甚至堆排序比快速排序复杂度还要稳定，在实际的软件开放中，快速排序的性能要比堆排序好，这是为什么呢?**</u>

1. 堆排序数据访问的方式没有快速排序友好。

   快速排序数据顺序访问（局部顺序访问），堆排序数据跳着访问，对CPU缓存不友好。

2. 对于同样的数据，在排序过程中，堆排序算法的数据交换次数要多于快速排序。

   快速排序数据交换的次数不会比逆序度多。

   堆排序第一步是建堆，会打乱数据原有的相对先后顺序，导致元数据的顺序度降低。

   <u>**实验：可以计算快速排序和堆排序的数据交换次数。**</u>



问题：

1. 对于完全二叉树来说，下标从n/2+1到n的都是叶子节点，这个结论是怎么推导出来的？
2. 堆的其他应用？

![堆的叶子节点证明&堆的应用](/Users/yangzanjie/code/study/数据结构和算法/堆的叶子节点证明&堆的应用.jpg)

应用：

1. top k
2. 流里面的中值
3. 流里面的中位数



### 17.2

<u>**堆的应用**</u>

- 优先级队列

  优先级最高的，最先出队。

  1. 合并有序小文件

     数组的做法，不高效。

     堆，小顶堆的做法。删除堆顶数据和插入数据的时间复杂度，都是O(logn)。

  2. 高性能定时器

- 利用堆求Top K

  维护大小为K的小顶堆

  1. 针对静态数据
  2. 针对动态数据

- 利用堆求中位数

  中位数--处在中间位置的那个数，奇数个，中间那个就是，偶数个，两个中的任意一个。

  对于一组静态数据，中位数固定，可以先排序，尽管排序成本大，但数据固定，边际成本很小。

  对于动态数据集合，中位数在不停变动 ，针对静态的方法，效率很低。

  借助堆这种数据结构，不用排序，就可以非常高效的实现中位数操作。

  维护两个堆，一个大顶堆，一个小顶堆，大顶对堆存储前半部分数据，小顶堆存储后半部分数据，且小顶堆中的数据都大于大顶堆中的数据。



<u>**Q：假设有一个包含10亿个搜索关键词的日志文件，如何能快速获取到热门榜Top10的搜索关键词呢？**</u>

[](https://time.geekbang.org/column/article/70187)



<u>**问题**</u>

有一个访问量非常大的网站，我们希望将点击量排名Top 10的新闻摘要，滚动显示在网站首页banner上，并且每隔一小时更新一次。如果你是负责开发这个功能的工程师，你会如何来实现呢？

------



## 18 图 Graph

如何理解图？

![图](/Users/yangzanjie/code/study/数据结构和算法/图.jpg)

图中的元素叫做顶点vertex，图中的一个顶点可以与其他任意顶点建立连接关系，这种建立的关系叫做边edge。

顶点的度degree，跟顶点相连接的边的条数。

引入边的“方向”概念：有向图，无向图。

![有向图](/Users/yangzanjie/code/study/数据结构和算法/有向图.jpg)

有向图中，度分为：

- 入度In-degree，表示有多少条边指向这个顶点。
- 出度Out-degree，表示有多少条边是以这个顶点为起点指向其他顶点。



带权图weighted graph，每条边有一个权重weight。（表示qq好友间的亲密度。）



<u>**邻接矩阵的存储方法**</u>

图最直观的一种存储方法，邻接矩阵(Adjacency Matrix)。

![图的邻接矩阵存储方法](/Users/yangzanjie/code/study/数据结构和算法/图的邻接矩阵存储方法.jpg)

- 缺点

  浪费空间。还有存储的是稀疏图Sparse Matrix，顶点很多，每个顶点的边并不多，邻接矩阵存储方法就回更浪费空间。

- 优点

  存储方式简单、直接，因为基于数组，在获取两个顶点的关系时，非常高效，此外，方便计算。因为用邻接矩阵的方式存储图，可以将很多图的运算转换成矩阵之间的运算。例如Floyd-Warshall算法求解最短路径问题。



<u>**邻接表存储方法**</u>

邻接表Adjacency List

![图的邻接表 存储方法](/Users/yangzanjie/code/study/数据结构和算法/图的邻接表 存储方法.jpg)

时间、空间复杂度互换的设计思想。

- 优点

  省空间

- 缺点

  用起来耗时，链表的存储方式对缓存不友好。

但是，可以对链表进行改进，提高查找效率，比如平衡二叉树等，在实际开发中，可以选择用红黑树。也可以用其他动态数据结构，比如跳表、散列表等。还可以将链表改成有序动态数组，通过二分查找法来快速定位两个顶点之间是否存在边。



<u>**Q：如何存储微博、微信等这些社交网络中的好友关系？**</u>

微博，有向图

微信，无向图





<u>**问：**</u>

1. 微信这种无向图，应该如何存储？
2. 符合图这种结构特点的例子还有很多，比如知识图谱(Knowledge Graph)，关于图这种数据结构，还有其他例子吗？

------



## 19  搜索

<u>**什么是“搜索”算法？**</u>

（暴力搜索算法）深度优先搜索算法、广度优先搜索算法基于图这种数据结构，既可用于无向图，也可用于有向图。



<u>**广度优先搜索算法（BFS）**</u>

Breadth-First-Search。

![广度优先搜索算法](/Users/yangzanjie/code/study/数据结构和算法/广度优先搜索算法.jpg)

[](https://time.geekbang.org/column/article/70891)

pre、visited、print变量。

时间复杂度O(E)，E为边的个数。

空间复杂度O(V)，V为顶点的个数。



<u>**深度优先搜索DFS**</u>

Depth-First-Search，最直观的例子“走迷宫”。

![深度优先搜索示例](/Users/yangzanjie/code/study/数据结构和算法/深度优先搜索示例.jpg)

回溯思想。

并不是 最优路径。

递归实现。

pre、visited、print、found变量。

时间复杂度，每条边最多被访问两次，一次是遍历，一次是回退，所以时间复杂度是O(E)，E表示边的个数。

空间复杂度，O(V)，V代表顶点个数。



<u>**Q：给你一个用户，如何找出这个用户的所有三度（其中包含一度、二度和三度）好友关系？**</u>

稍加改造广度搜索算法。



<u>**问题：**</u>

1. 能否用深度搜索算法，实现三度搜索？
2. 如何将迷宫抽象成一个图？如何在计算机中存储一个迷宫？

------



## 20 字符串匹配

### 20.1  BF算法、RK算法

<u>**Q：RK算法如何借助哈希算法来实现高效字符串匹配？**</u>



<u>**BF算法**</u>

Brute Force 暴力匹配算法、朴素匹配算法。

主串，模式串。

尽管理论上，BF时间复杂度很高，但是实际开发中常用。

原因：

- 大部分情况下，模式串 和主串的长度都不会太长。而且，每次模式串与主串中的子串匹配时，遇到不能匹配的就停止了。尽管理论上最坏情况时间复杂度是O(n*m)，但是，统计意义上，大部分情况下，算法执行效率要比这个高很多。
- 算法思想简单，代码实现也简单，在工程中，在满足性能要求的前提下，简单是首选。KISS设计原则，keep it simple and stupid原则。



<u>**RK算法**</u>

Rabin-Karp算法，是BF算法的升级版。

引入哈希算法，时间复杂度会降低。

通过哈希算法，对主串中的n-m+1个子串分别求哈希值，然后逐个与模式串的哈希值比较大小。因为哈希值是一个数字，数字之间的比较是否相等是非常快速的。

但是，这么做整体效率没有提高，需要遍历子串中的每个字符。

需要提高哈希算法计算子串哈希值的效率。

。。。略。。。

<u>**时间复杂度O(n)。**</u>

效率取决于哈希算法的设计方法，如果存在冲突，时间复杂度可能会退化，极端情况下，哈希算法存在大量冲突，时间复杂度会退化为O(n*m)。



<u>**问：**</u>

上述为一维字符串的匹配方法，实际上，BF算法和RK算法都可以类比到二维空间，所以，如何在一个二维字符串矩阵中查找另一个二维字符串矩阵呢？



### 20.2 BM算法Boyer-Moore

<u>**Q：文本编辑器的查找功能，是用哪种算法来实现的？有没有比BF和RK更高效的算法？**</u>



<u>**BM算法**</u>

核心思想：在模式串与主串匹配过程中，当模式串与主串某个字符串不匹配的时候，能够跳过一些肯定不会匹配的情况，将模式串往后多滑动几位。



<u>**算法原理分析**</u>

1. 坏字符规则

   最好时间复杂度O(n/m)

2. 好后缀规则

   - 在模式串中，查找跟好后缀匹配的另一个字符串；	
   - 在好后缀中的后缀子串中，查找最长的、能跟模式串前缀子串匹配的后缀子串。



<u>**实现**</u>



太难了。啃不动了。



### 20.3 KMP算法

<u>**核心思想：找到一些规律，将模式串往后多滑动几位，跳过那些肯定不会匹配的情况。**</u>



[](https://www.zhihu.com/question/21923021?utm_source=wechat_search&utm_medium=organic)



暴力思路：子串和模式串逐个字符比较，发生不匹配时，两者都回退，然后重新比较，如此遍历。



思想：子串不回退，只前进，由模式串来回退，减少处理步骤，加速匹配。



模式串回退到，上一步骤比较的字符串长度的最大匹配数位置，继续比较。



<u>**要点一：求模式串每个字符位置的最大匹配数的数组。**</u>

又名为部分匹配表。Partial Match Table。

数组的下标值，为[0，模式串的长度-1]，表明子串的长度。

值为，该长度下的子串的最大匹配子串的长度。

次大匹配：匹配中的匹配。

对于一个字符串，在比较时，当前字符的次大匹配，即，上一个字符对应的最大匹配。

若当前字符的次大匹配字符串的后面一个字符，与当前字符相等，那么当前字符的最大匹配就是，次大匹配+1。

若是不相等，则与当前字符串的次大匹配的字符串的次大匹配的后面一个字符，进行比较，如此循环，当最大匹配为0时，还没有相等的，那当前字符的最大匹配就是0了。



<u>**要点二：子串不回退，模式串回退到，上一步骤比较的字符串长度的最大匹配数位置，继续比较。**</u>



------



## 21 Trie树



本质，利用字符串之间的公共前缀，将重复的前缀合并在一起。



<u>**如何实现一棵Trie树？**</u>

了解Trie树的主要操作：

- 将字符串集合构造成Trie树
- 查询一个字符串

那么，如何存储一个Trie树？

略。。。

时间复杂度：

构建，O(n)，n表示所有字符串的长度和。

查询，O(k)，k表示要查询的字符串的长度。

浪费内存？

解决方法：稍微牺牲一点查询效率，将每个节点中的数组替换成其他数据结构，来存储一个节点的子节点指针，例如有序数组、跳表、散列表、红黑树等。

例如用有序数组，查询可用二分查找，插入的时候，为了维护有序性，会稍微慢点。



Trie树变体，例如缩点优化。



<u>**Trie树与散列表、红黑树的比较**</u>

字符串的匹配问题，笼统的讲，就是数据的查找问题。对于支持动态数据高效操作的数据结构，比如散列表、红黑树、跳表等等。

对于在一组字符串中查找字符串，Trie树的表现其实并不好，它堆要处理的字符串有及其严苛的要求。

1. 字符串中包含的字符集不能太大。否则存储空间会浪费很多，即便可以优化，也要付出牺牲查询、插入效率的代价。
2. 要求字符串的前缀重合比较多，不然空间消耗会变大很多。
3. 要用Trie树解决问题的话，需要从零开始实现一个Trie树，还要保证没有bug，这在工程上，是将简单问题复杂化，除非必须，一般不建议这么做。
4. 通过指针串起来的数据块是不连续的，Trie树用到了指针，所以对缓存是不友好的，性能上会打折扣。

综上几点，针对一组字符串中查找字符串的问题，在工程中，更倾向于用散列表或者红黑树。这两种数据结构，不需要自己去实现，直接利用编程语言中提供的现成类库就行了。



Trie树不适合精确查找，但比较适合查找前缀匹配的字符串。



<u>**问题：如果现在给你一个很大的字符串集合，比如包含1万条记录，如何通过编程量化分析这组字符串集合是否比较适合用Trie树解决呢？即，如何统计字符串的字符集大小，以及前缀重合的程度？**</u>





## 22 AC自动机

前言：网站上的敏感词过滤功能，如何实现的？对于访问量巨大的网站来说，性能要求十分高。

<u>**Q：如何实现一个高性能的敏感词过滤系统？**</u>



<u>**基于单模式串和Trie树实现的敏感词过滤**</u>

前述将的BF算法、RK算法、BM算法、KMP算法，都是单模式串匹配算法，Trie树是多模式串匹配算法。

单模式串匹配：一个模式串和一个主串之间进行匹配，在一个主串中查找一个模式串。

多模式匹配：在多个模式串和一个主串之间做匹配，在一个主串中查找多个模式串。

使用单模式串匹配完成多模式串的工作，十分低效。

要点：<u>**用Trie树实现敏感词过滤**</u>。

对敏感词进行预处理，构建成Trie树结构，这个预处理只需要做一次，如果敏感词字典动态更新了，比如删除、添加了一个敏感词，只需要动态更新一下Trie树就可以了。

当用户输入一个文本内容后，将用户输入的内容作为主串，从第一个字符（假设是C）开始，在Trie树匹配。当匹配到Trie树的叶子节点，或者中途匹配遇到不匹配字符的时候，将主串的开始匹配位置后移一位，也就是从字符C的下一个字符开始，重新在Trie树中匹配。



<u>**借鉴思想：**</u>这个类似于单模式串匹配的BF算法。单模式串匹配算法中，KMP算法对BF算法进行改进，引入了next数组，让匹配失败时，尽可能将模式串往后多滑动几位。



<u>**经典的多模式串匹配算法：AC自动机**</u>

Aho-Corasick算法，AC自动机，在Trie树之上，加入了类似KMP的next数组，只不过此next数组是构建在树上罢了。

```java
public class AcNode {
  public char data; 
  public AcNode[] children = new AcNode[26]; // 字符集只包含 a~z 这 26 个字符
  public boolean isEndingChar = false; // 结尾字符为 true
  public int length = -1; // 当 isEndingChar=true 时，记录模式串长度
  public AcNode fail; // 失败指针
  public AcNode(char data) {
    this.data = data;
  }
}
```

Ac自动机的构建，包含两个操作：

- 将多个模式串构建成Trie树；
- 在Trie树上构建失败指针（相当于KMP中的失效函数next数组）

略略略



<u>**思考：各个字符串匹配算法的特点和比较适合的应用场景？**</u>

![各字符串匹配算法特点和使用场景](/Users/yangzanjie/code/study/数据结构和算法/各字符串匹配算法特点和使用场景.jpg)

------



4个算法思想：贪心、分治、回溯、动态规划。



## 23 贪心算法 Greedy Algorithm

经典的应用：霍夫曼编码Huffman Coding，Prim和Kruskal最小生成树算法，Dijkstra单源最短路径算法。

<u>**如何利用贪心算法实现对数据压缩编码，有效节省存储空间？**</u>



<u>**如何理解贪心算法？**</u>

1. <u>**当看到这类问题的时候，首先要联想到贪心算法：**</u>针对一组数据，定义了限制值和期望值，希望从中选出几个数据，在满足限制值的情况下，期望值最大。
2. <u>**尝试看下这个问题是否可以用贪心算法解决：**</u>每次选择当前情况下，在对限制值同等贡献量的情况下，对期望值贡献最大的数据。
3. <u>**举几个例子看下贪心算法产生的结果是否是最优的：**</u>大部分情况下，举几个例子验证下就可以了。严格证明贪心算法的正确性，非常复杂。



<u>**注：实际上，用贪心算法解决问题的思路，并不总能给出最优解。**</u>

例如，前面的选择会影响后面的选择的问题类型。



<u>**实战分析：**</u>

1. 分糖果
2. 钱币找零
3. 区间覆盖



<u>**如何利用贪心算法实现对数据压缩编码，有效节省存储空间？**</u>

根据贪心思想，将出现频率比较多的字符，用稍微短一些的编码；出现频率比较少的字符，用稍微长一些的编码。

略略略。。。



实际上，贪心算法适用的场景比较有限，更多的是指导设计基础算法。比如最小生成树算法、单源最短路径算法，这些都用到了贪心算法。<u>**不要刻意记忆贪心算法原理，多联系才是最有效的学习方法。**</u>



最难的一块：如何将要解决的问题抽象成贪心算法模型。。。



<u>**思考：**</u>

1. 在一个非负整数a中，我们希望从中移除k个数字，让剩下的数字值最小，如何选择移除哪k个数字呢？
2. 假设有n个人等待被服务，但是服务窗口只有一个，每个人需要被服务的时间长度是不同的，如何安排被服务的先后顺序，才能让这n个人总的等待时间最短？

------



## 24 分治算法 divide and conquer

Google大数据处理三驾马车：MapReduce、GFS、Bigtable。

MapReduce在倒排索引、PageRank计算、网页分析等搜索引擎相关的技术中都有大量的应用。

MapReduce的本质：分治算法。



<u>**如何理解分治算法？**</u>

分而治之。

将原问题划分成n个规模较小，并且结构与原问题相似的子问题，递归地解决这些子问题，然后再合并其结果，就得到原问题的解。

<u>**分治算法是一种处理问题的思想，递归是一种编程的技巧。**</u>



分治算法的递归实现中，每一层递归都会涉及这样三个操作：

- 分解：将原问题分解成一系列子问题；
- 解决：递归地求解各个子问题，若子问题足够小，则直接求解；
- 合并：将子问题的结果合并成原问题。



分治算法能解决的问题，一般需要满足下面这些条件：

- 原问题与分解成的小问题具有相同的模式；
- 原问题与分解成的子问题可以独立求解，子问题之间没有相关性，与动态规划有明显的区别；
- 具有分解终止条件，即，当问题足够小的时候，可以直接求解；
- 可以将子问题合并成原问题，且合并操作的复杂度不能太高，否则就起不到减小算法总体复杂度的效果了。



<u>**应用举例分析：**</u>

1. 如何编程求出一组数据的有序对个数或者逆序对个数？
2. 二维平面上有n个点，如何快速计算出两个距离最近的点对？
3. 有两个n*n的矩阵A，B，如何快速求解两个矩阵的乘积C=A乘B？



<u>**在海量数据处理中的应用：**</u>

分治处理思路，克服内存的限制，还能利用多线程或者多机制处理，加快处理的速度。



<u>**思考：用到了分治算法思想的例子**</u>*？



------



## 25  实战测试

[](https://time.geekbang.org/column/article/73786)

目前状态：处于看到题目，能想到在什么章节出现，但是细节模糊。

最好每个题目，当做一个小项目，做一下。

------



## 26 回溯算法 Backtracking Algotithm

深度优先搜索算法，利用的就是回溯算法思想。

应用广泛，例如正则表达式匹配、编译原理中的语法分析等。

经典的数学问题可以用回溯算法解决，例如数独、八皇后、0-1背包、图的着色、旅行商问题、全排列等等。



<u>**如何理解“回溯算法”？**</u>

回溯算法很多时候应用在“搜索”这类问题上，这里说的搜索，是指在一组可能的解中，搜索满足期望的解。

处理思想，类似枚举搜索。枚举所有的解，找到满足期望的解。为了有规律的枚举所有可能的解，避免遗漏和重复，把问题求解的过程分为多个阶段。每个阶段，都会面对一个岔路口，先随意选一条路走，当发现这条路走不通的时候，回退到上一个岔路口，另选一种走法继续。



举例：“八皇后”问题。



<u>**理论知识容易懂，难的是用递归实现。**</u>

两个经典应用：

1. 0-1背包

   经典解法：动态规划。

   不那么高效的解法：回溯法。

2. 正则表达式



<u>**思考：对0-1背包问题稍加改造，如果每个物品不仅重量不同，价值也不同。如何在不超过背包重量的情况下，让背包中的总价值最大？**</u>



------



## 27 动态规划 Dynamic Programming 

### 27.1 base

适合求解最优问题，比如求解最大值、最小值等等。

可以非常显著的降低时间复杂度，提高代码执行效率。

<u>**难点：类似于递归，求解问题的过程不太符合人类常规的思维方式。**</u>



<u>**0-1背包问题**</u>

略

<u>**0-1背包问题升级版**</u>

略      <u>**优化自己写**</u>



<u>**思考：**</u>

“杨辉三角”，假设你站在第一层，往下移动，把移动到最底层所经过的所有数字之和，定义为路径的长度。编程求出从最高层移动到最底层的最短路径长度。

![动态规划--杨辉三角](/Users/yangzanjie/code/study/数据结构和算法/动态规划--杨辉三角.jpg)





### 27.2 理论

理论：

1. 什么样的问题可以用动态规划解决？
2. 解决动态规划问题的一般思考过程会什么样的？
3. 贪心、分治、回溯、动态规划这四种算法有什么区别和联系？



<u>**一个模型三个特征**</u>：

1. <u>**什么是一个模型？**</u>

   指动态规划解决的问题的模型，定义为“多阶段决策最优解模型”。

   一般用动态规划解决最优问题。解决问题的过程，需要经历多个决策阶段，每个决策阶段都对应着一组状态。然后，寻找一组决策序列，经过这组决策序列，能够产生最终期望求解的最优值。

2. <u>**三个特征**</u>

   - <u>**最优子结构**</u>

     指问题的最优解包含子问题的最优解。

     反过来说，通过子问题的最优解，推导出问题的最优解。

     对应到前述模型上，也可理解为，后面阶段的状态可以通过前面阶段的状态推导出来。

   - <u>**无后效性**</u>

     两层含义，第一层，在推导后面阶段状态的时候，只关心前面阶段的状态，不关心这个状态是怎么一步一步推导出来的。

     第二层含义，某阶段状态一旦确定，就不受之后阶段的决策影响。

     比较宽松，只要满足模型，基本都满足无后效性。

   - <u>**重复子问题**</u>

     不同的决策序列，到达某个相同的阶段时，可能会产生重复的状态。

<u>**实例：**</u>

​    略



<u>**两种动态规划结题思路总结**</u>

1. 状态转移表法

   一般能用动态规划解决的问题，都可以使用回溯算法的暴力搜索解决。

2. 状态转移方程法

   有点类似递归的解题思路。

   根据最优子结构，写出递归公式，即<u>**状态转移方程**</u>，是解决动态规划的关键。

   两种代码实现方式：

   - <u>**递归加“备忘录”**</u>
   - <u>**迭代递推**</u>



<u>**注意：不是每个问题都同时适合这两种解题思路，有的可能适合第一个，有的可能用第二个思路更清晰，因此要结合具体问题，选择用哪种。**</u>



<u>**四种算法思想比较分析**</u>

贪心、回溯、动态规划，可以分为一类，解决问题的模型，可以抽象成多阶段决策最优解模型。

分治，一类，尽管也是求最优解模型，但大部分不能抽象成多阶段决策模型。

回溯，是“万金油”，基本上贪心、动态规划能解决的，它都行，它相当于穷举法。时间复杂度非常高，指数级别，适合小规模数据问题。

动态规划比回溯高效，但并不适用于所有问题，需要满足一个模型三个特征。其之所以高效，是因为回溯算法实现中存在大量的重复子问题。

贪心算法，是动态规划的一种特殊情况，满足三个条件，最优子结构、无后效性、贪心选择性。贪心选择性，是指通过局部最优的选择，能产生全局的最优选择。局部最优解构成全局最优解。



<u>**思考：**</u>![动态规划-理论篇-思考](/Users/yangzanjie/code/study/数据结构和算法/动态规划-理论篇-思考.jpg)

硬币找零问题



### 27.3

<u>**目标：如何实现搜索引擎中的拼写纠错功能？**</u>



<u>**如何量化两个字符串的相似度？**</u>

<u>**编辑距离Edit Distance**</u>，一个非常著名的量化方法。

指将一个字符串转化成另一个字符串，需要的最少编辑操作次数（比如，增加一个字符、删除一个字符、替换一个字符）。

<u>**计算方式**</u>

根据所包含的编辑操作种类的不同，有多种计算方式，例如莱文斯坦距离，允许增加、删除、替换这三个操作；最长公共子串长度，允许增加、删除这两个操作。



![动态规划-leetcode](/Users/yangzanjie/code/study/数据结构和算法/动态规划-leetcode.jpg)



<u>**思考：**</u>

一个数字序列包含n个不同的数字，如何求出这个序列中的最长递增子序列长度？比如2，9，3，6，5，1，7这样一组数字序列，它的最长递增子序列就是2，3，5，7，所以最长递增子序列的长度就是4。

------



# 高级篇



## 28 拓扑排序

<u>**如何确定代码源文件的编译依赖关系？**</u>

编译器通过分析源文件或者程序员事先写好的编译配置文件(比如Makefile文件)，来获取源文件局部的依赖关系。

编译器如何通过源文件两两之间的局部依赖关系，确定一个全局的编译顺序？

```java
public class Graph {
  private int v; // 顶点的个数
  private LinkedList<Integer> adj[]; // 邻接表

  public Graph(int v) {
    this.v = v;
    adj = new LinkedList[v];
    for (int i=0; i<v; ++i) {
      adj[i] = new LinkedList<>();
    }
  }

  public void addEdge(int s, int t) { // s 先于 t，边 s->t
    adj[s].add(t);
  }
}
```



拓扑排序，基于有向无环图的一个算法。

1. Kahn算法
2. DFS深度优先搜索算法



<u>**思考：**</u>

![拓扑排序思考](/Users/yangzanjie/code/study/数据结构和算法/拓扑排序思考.jpg)

------



## 29 最短路径

<u>**问：地图软件是如何计算出最优出行路径的？**</u>



深度优先、广度优先，针对无权图的搜索算法。

针对有权图，如何计算两点之间的最短路径（经过的边的权重和最小）。



解决软件开发中的实际问题，最重要的一点就是<u>**建模**</u>，即将复杂的场景抽象成具体的数据结构。



<u>**单源最短路径算法**</u>



<u>**Dijkstra最短路径算法**</u>



思考：略

------



## 30 位图

网页爬虫

爬虫工作原理，通过解析已经爬取页面中的网页链接，然后再爬取这些链接对应的网页。

同一个网页链接有可能被包含在多个页面中，这就会导致爬虫在爬取的过程中，重复爬取相同的网页。那么，<u>**如何避免这些重复的爬取呢？**</u>

思路：在爬取一个新的网页之前，拿他的链接在已经爬取的网页链接列表中搜索。如果存在，则说明已经被爬取过了；如果不存在，则说明可以继续爬取，等爬取完后，将网页链接添加到已经爬取的网页链接列表中。

那么，<u>**如何记录已经爬取的网页链接呢？需要用什么样的数据结构呢？**</u>



<u>**算法解析**</u>

需要支持的操作：添加一个URL、查询一个URL

执行效率尽可能高。

处理的数据量大，内存消耗会很大，存储效率要尽可能高效。



满足这些条件的数据结构：散列表、红黑树、跳表这些动态数据结构，能够快速地支持插入、查找数据。

内存方面，以10亿个URL，一个URL平均长度64字节，需要大约60G。

若用散列表，考虑到散列因子，若用链表法，存储指针，可能会超100G。

考虑分治思想，用多台机器，例如20台内存为8G的机器。



<u>**继续优化**</u>

略



<u>**存储结构**</u>

<u>**位图BitMap**</u>

布隆过滤器



<u>**思考**</u>：

1. 假设有一亿个整数，数据范围是从1到10亿，如何快速并且省内存地给这个一亿个数据从小到大排序？
2. 在哈希函数中讲过的分治思想，用散列表以及哈希函数，实现海量图库中的判重功能，如果允许小概率的误判，那是否可以用布隆过滤器来解决？重新估算，用布隆过滤器需要多少台机器。



------





## 31 概率统计



<u>**Q：实现一个简单的垃圾短信过滤功能以及骚扰电话拦截功能，该用什么样的数据结构和算法呢？**</u>



1. <u>**基于黑名单的过滤器**</u>

   维护一个骚扰电话号码和垃圾短信发送号码的黑名单。

   黑名单的搜集，有很多途径，比如，可以从一些公开的网站上下载，也可以通过类似“360骚扰电话拦截”的功能，通过用户自主标记骚扰电话来收集。对于被多个用户标记，并且标记个数超过一定阈值的号码，可以定义为骚扰电话，加入到黑名单中。

   黑名单号码不多的话，可以使用散列表、二叉树等动态数据结构来存储，对内存的消耗并不会很大。如果每一个号码看作一个字符串，假设平均长度16个字节，那么存储50万个号码，大约10MB的内存空间。这个内存可以接受。

   但是，若黑名单有很多，比如有500万个，那么再用散列表的话，大约要100MB，为了实现这么一个功能，显然不合理。

   上一节讲的，布隆过滤器的最大特点就是比较节省内存，用来解决这个问题，十分适合。比如，存储500万个号码，把位图设置为10倍大小，就是5000万个bit，换算成字节，不到7MB的存储空间，比起散列表，内存的消耗少了很多。

   还有一种，时间换空间的方法，将内存的消耗优化到极致。

   将黑名单存储到服务器端上，将过滤和拦截的核心工作，交给服务端来做。

   不过，布隆过滤器有判错的概率，对于用户来说，误判是无法接受的，这是一个很大的问题。

   

2. <u>**基于规则的过滤器**</u>

   - 短信中包含特殊单词（或词语），比如一些非法、淫秽、反动词语等；
   - 略略略

   

3. <u>**基于概率统计的过滤器**</u>

   基础理论，基于朴素贝叶斯算法。



事实上，可以结合三种不同的过滤方式的结果，对同一个短信处理，如果三者都表明这个短信是垃圾短信，才把它当做垃圾短信，这样就会更准确。



实际工程中，还需要结合具体的场景，以及大量的实验，不断去调整策略，权衡垃圾短信判定的准确率和召回率，来实现需求。



<u>**思考：头脑风暴下，还有没有其他方法呢？**</u>



------



## 32 向量空间

<u>**如何实现一个简单的音乐推荐系统？**</u>



<u>**算法解析：**</u>

核心思想

- 找到跟你口味偏好相似的用户，把他们爱听的歌曲推荐给你
- 找出跟你喜爱的特征相似的歌曲，把这些歌曲推荐给你



1. <u>**基于相似用户做推荐**</u>

   

2. <u>**基于相似歌曲做推荐**</u>



这个问题是推荐系统的最典型的一类问题。

------



## 33 B+树

<u>**Q：数据库索引是如何实现的呢？底层使用的是什么数据结构和算法呢？**</u>



<u>**算法解析**</u>

<u>**思考的过程比结论更重要。**</u>



[](https://time.geekbang.org/column/article/77830)

------



## 34 搜索

<u>**Q：如何用A*搜索实现游戏中的自动寻路功能？**</u>



A*算法，是对Dijkstra算法的优化和改造。

[](https://time.geekbang.org/column/article/78175)

------



## 35 索引

<u>**Q：如何在海量数据中快速查找某个数据？**</u>



<u>**为什么需要索引？**</u>

软件开发的本质，对数据的存储和计算。

对应的，存储需要的就是数据结构，计算需要的就是算法。

对存储的需求，功能上无非就是增删改查，一旦数据很多，那么性能就成为了这些系统关注的重点。特别是在存储相关的基础系统（比如MySQL数据库、分布式文件系统等）、中间件（比如消息中间件RocketMQ等）中。

如何节省存储空间、如何提高增删改查效率，成为了设计了重点。这个的实现，离不开<u>**索引**</u>。



<u>**索引的需求定义**</u>

1. <u>**功能性需求**</u>

   考虑的点：

   - 数据是格式化数据，还是非格式化数据？
   - 静态数据，or动态数据？
   - 索引储存在内存还是硬盘，还是两者兼顾？
   - 单值查找，还是区间查找？
   - 单关键词查找，还是多关键词组合查找？
   - 等等。。。。

2. <u>**非功能性需求**</u>

   - 不管是在内存中，还是在磁盘中，索引堆存储空间的消耗不能过大
   - 在考虑索引查询效率的同时，还要考虑索引的维护成本



<u>**构建索引的常用数据结构有哪些？**</u>

前述讲的几种支持动态数据集合的数据结构，例如，散列表、红黑树、跳表、B+树。此外，位图、布隆过滤器可以辅助索引，有序数组可以对静态数据构建索引。

- <u>**散列表**</u>，增删改查性能十分好，时间复杂度O(1)。一些键值数据库，例如Redis、Memcache，是用散列表来构建索引的，一般建在内存中。
- <u>**红黑树**</u>，一种常用的平衡二叉树，增删查的时间复杂度时O(logn)，适合用来构建内存索引。Ext文件系统中，对磁盘块的索引，就是用红黑树。
- <u>**B+树**</u>，相比于红黑树，适合用于构建在磁盘中的索引。大部分关系型数据库的索引，比如MySQL、Oracle都是用B+树来实现的。
- <u>**跳表**</u>，也支持快速添加、删除、查找数据。通过灵活调整索引结点个数和数据个数之间的比例，可以很好平衡索引堆内存的消耗及其查询效率。Redis中的有序集合就是用跳表做的。

<u>**辅助存储在磁盘中的索引，加速数据查找效率**</u>

<u>**布隆过滤器**</u>，对于判定存在的数据，可能会误判，但是判定不存在的数据，那绝逼不存在的，而且占用内存十分少。

因此，可以针对数据，构建一个布隆过滤器，存储在内存中。当查询数据的时候，可以先通过布隆过滤器，判定是否存在。



此外，有序数组其实也可以作为索引。数据若是静态的，不会有增删改。可以把数据的关键词抽取出来，组织成有序数组，用二分法来快速查找数据。



<u>**思考：基础系统、中间件、开源软件等系统中，有哪些用到了索引？这些系统的索引是如何实现的呢？**</u>

------



## 36 并行算法

<u>**当算法无法再继续优化的情况下，该如何来进一步提高执行效率？**</u>

<u>**如何借助并行计算的处理思想对算法进行改造？**</u>



<u>**并行排序**</u>

<u>**并行查找**</u>

<u>**并行字符串匹配**</u>

<u>**并行搜索**</u>



<u>**思考：假设我们有n个任务，为了提高执行的效率，我们希望能并行执行任务，但是各个任务之间又有一定的依赖关系，如何根据依赖关系找出可以并行执行的任务？**</u>



------



## 37 Redis常用类型对应的数据结构

### 37.1 

<u>**Redis**</u>，key-value<u>**键值数据库**</u>。

主要作为内存数据库来使用，也支持将数据存储在硬盘中。

键的类型是字符串，值的类型有很多，常用的有字符串、列表、字典、集合、有序集合。



<u>**列表List**</u>

- 压缩列表
- 双向循环列表

<u>**字典Hash**</u>

- 压缩列表
- 散列表

<u>**集合Set**</u>

- 基于有序数组
- 基于散列表

<u>**有序集合sortedset**</u>

- 跳表
- 压缩列表（数据量小的时候）

<u>**数据结构持久化**</u>

（数据结构的持久化问题、对象的持久化问题）

两种思路

- 清除原有的存储结构，只将数据存储到磁盘中，还原时，再将数据组织成原来的数据结构。Redis采用的就是这种思路。弊端：还原的过程，耗时较多。
- 保留原来的存储格式，将数据按照原有的格式存储在磁盘中。



<u>**思考：**</u>

1. 在数据量较小的情况下，Redis中的很多数据类型，比如字典、有序集合等，都是通过多种数据结构来实现的，为什么会有这样的设计呢？用一种固定的数据结构来实现，不是更加简单吗？
2. 数据结构持久化有两种方法，对于二叉查找树这种数据结构，如何将它持久化到磁盘中？





### 37.2

<u>**搜索引擎背后的经典数据结构和算法**</u>



搜索引擎，一个技术驱动的产品，因为实现起来，技术难度非常大，技术好坏直接决定这个产品的核心竞争力。



搜集、分析、索引、查询



<u>**自己实现一个demo**</u>



<u>**思考：**</u>

1. 图的遍历方法有两种，深度优先和广度优先。搜索引擎中的爬虫通过广度优先策略来爬取网页。搜索引擎为什么选择广度优先策略，而不是深度优先策略？
2. 大部分搜索引擎在结果显示的时候，都支持摘要信息和网页快照。实际上，只要针对这个设计思路，稍加改造，就可以支持这两项功能，要如何改造呢？



------



## 38 高性能队列Disruptor背后的数据结构和算法

Disruptor，一种内存消息队列，从功能上有点类似Kafka。但Disruptor是线程之间用于消息传递的队列。在Apache Storm、Camel、Log4j 2等很多知名项目中都有广泛的应用。

比Java中另一个非常常用的内存消息队列ArrayBlockingQueue(ABS)的性能，搞一个数量级，可以算是最快的内存消息队列。



<u>**基于循环队列的“生产者-消费者模型”**</u>

生产者-消费者模型，生产者，生产数据，放到一个中心存储容器，消费者，从中心存储容器中，取出数据消费。

中心存储容器，最常用的数据结构，队列（支持先进先出特性）。

队列的实现思路：基于链表的，基于数组的，不同的需求背景，使用不同的实现。

非循环队列，在添加、删除数据的工程中，会涉及数据的搬移操作，导致性能变差。循环队列可以解决这个问题，性能更好，因此，大部分用到顺序队列的场景中，都选择用顺序队列中的循环队列。



<u>**基于加锁的并发“生产者-消费者模型”**</u>

前述方法，多线程时，存在问题：

- 多个生产者写入的数据可能会相互覆盖；
- 多个消费者可能会读取重复的数据；

加锁，将并行改成串行。

但会导致执行效率下降，继续优化代码，用CAS（compare and swap，比较交换）操作等减少加锁的粒度。



<u>**基于无锁的并发“生产者-消费者模型”**</u>

Disruptor采用了另一种思路实现。

生产者，往队列添加数据之前，先申请可用空闲存储单元，并且是批量的申请连续的n（n>=1）个存储单元。当申请到这组连续的存储单元之后，后续往队列中添加元素，就可以不用加锁了，因为这组存储单元是这个线程独享的。不过，申请存储单元的过程是需要加锁的。

消费者，处理思路类似生产者。先申请，后续操作不用加锁了。

弊端：



<u>**思考：**</u>

为了提高存储性能，我们往往通过分库分表的方式设计数据库表，假设我们有8张表用来存储用户信息。这个时候，每张用户表中的字段不能通过自增的方式来产生，因为这样做，会导致不同表之间的用户ID值重复。

为了解决这个问题，需要实现一个ID生成器，可以为所有的用户表生成唯一的ID号。<u>**那么如何设计一个高性能的、支持并发的、能够生成全局唯一ID的ID生成器？**</u>

------



## 39 微服务接口鉴权限流背后的数据结构和算法

<u>**微服务**</u>，简单点讲，就是把复杂的应用，解耦拆分成几个小的应用。

好处：有利于团队组织结构的拆分，每个应用可以独立运维，独立扩容，独立上线，各个应用之间互不影响。

弊端：服务之间的调用关系变得复杂，平台的整体复杂熵升高、出错的概率、debug问题的难度都高了好几个数量级。<u>**服务治理成了微服务的一个技术重点。**</u>



服务治理：简单点讲，就是管理微服务，保证平台整体正常，平稳地运行。内容较多，比如鉴权、限流、降级、熔断、监控告警等等 。



<u>**鉴权背景**</u>

限制微服务访问接口的权限。



<u>**如何实现？**</u>

接口格式有很多。例如Dubbo的RPC接口、类似Spring Cloud这样的HTTP接口。不同接口的实现类似。

以HTTP接口为例。

原理简单。实现层面，该用什么数据结构？

1. 如何实现精确匹配规则？

   规则存储，采用散列表。

   可以将每个应用对应的权限规则，存储在一个字符串数组中。当用户请求到来时，拿用户的请求URL，在这个字符串中逐一匹配，匹配算法就是之前学过的字符串匹配算法（例如KMP、BM、BF等）。

   规则不会经常变动，所以为了加快匹配速度，可以按照字符串的大小给规则排序，把它组织成有序数组这种数据结构。当查找某个URL能否匹配其中某条规则时，可以采用二分查找算法，在有序数组中进行匹配。

   二分法O(logn)对比顺序法O(n)

   对于规则中接口长度比较长，鉴权功能调用量非常大的情况，这种优化方法带来的性能提升还是非常可观的。

2. 如何实现前缀匹配规则？

   Trie树适合用来做前缀匹配。针对这个需求，可以将每个用户的规则集合，组织成Trie树这种数据结构。

   规则不会经常变动，可以将每个节点的子节点组织成有序数组这种数据结构，在匹配时，利用二分查找算法。

3. 如何实现模糊匹配规则？

   规则更加复杂，包含通配符，比如"**"表示匹配任意多个子目录。只要用户请求URL可以跟某条规则模糊匹配，就说这条规则适合于这个请求。

   不同的应用对应不同的规则集合，可以用散列表存储这个对应关系。 

   <u>**每个用户对应的规则集合，该用什么数据结构来存储？针对这个包含通配符的模糊匹配，该用什么算法来实现呢？**</u>

   回溯算法----正则表达式

   借助这个思路，拿请求URL跟每条规则逐一模糊匹配。

   时间复杂度较高，优化一下，将不包含通配符的规则和包含通配符的规则分开处理。



<u>**限流背景**</u>

限流，对接口的调用频率进行限制，比如每秒钟不能超过100次调用，超过之后，就拒绝服务。

原理简单，但在很多场景中，发挥着重要作用。比如在秒杀、大促、双11、618等场景中，限流已经成为保证系统平稳运行的一种标配解决方案。

按照不同的限流粒度，限流可以分为很多种类型。比如给每个接口限制不同的访问频率，或者给所有接口限制总的访问频率。

<u>**如何实现精准限流？**</u>

最简单，<u>**固定时间窗口限流算法**</u>。

缺点：限流策略过于粗略，无法应对两个时间窗口临界时间内的突发流量。

为了解决这个问题，可以限制任意时间窗口（比如1s）内，接口请求树都不能超过某个阈值，这个算法叫<u>**滑动时间窗口限流算法**</u>。

维护一个队列。略。。。。

但是仍然不能防止，在细粒度上访问过于集中的问题。。。

还有很多更加平滑的限流算法，比如令牌桶算法、漏桶算法等。。。



<u>**思考：**</u>

1. 除了用循环队列来实现滑动时间窗口限流算法之外，是否还可以用其他数据结构来实现呢？对比一下这些数据结构跟循环队列在解决这个问题时的优劣之处。
2. 分析一下鉴权部分，前缀匹配算法的时间复杂度和空间复杂度。

------



## 40 短网址系统

短网址服务，将一个长的网址转化成一个短的网址。

<u>**如何实现的？底层依赖了哪些数据结构和算法呢？**</u>



还有一个功能，短网址服务，将短网址重定向为原始网址。



<u>**如何通过哈希算法生成短网址？**</u>

短网址服务里，不需要考虑反向解密的难度，只需要关心哈希算法的计算速度和冲突概率。

满足和这样要求的哈希算法有很多，比较著名的并且应用广泛的一个哈希算法，MurmurHash算法。



1. <u>**如何让短网址更短？**</u>

   使用更高进制。

2. <u>**如何解决哈希冲突问题？**</u>

   略

3. <u>**如何优化哈希算法生成短网址的性能？**</u>

   略



<u>**如何通过ID生成器生成短网址？**</u>

可以维护一个ID自增生成器。它可以生成1、2、3...这样自增的整数ID。短网址服务接受转化请求后，从ID生成器中取一个号码，然后将其转化成62进制表示华，拼接到短网址服务的域名。

1. 相同的原始网址可能会对应不同的短网址
2. 如何实现高性能的ID生成器
   - 第一种思路，给ID生成器装多个前置发号器，批量地给每个前置发号器发送ID号码。接受到短网址生成请求时，选一个前置发号器来取号码。通过多个前置发号器，明显提高了并发发号的能力。
   - 第二种思路，直接实现多个ID生成器同时服务。为保证每个ID生成器的ID不重复，要求每个ID生成器按照一定的规则。



<u>**思考：**</u>

1. 需要额外支持用户自定义短网址功能（http://t.cn/{用户自定义部分}），该如何改造上述算法？
2. 讲述通过ID生成器生成短网址，问题1相同的原始网址可能会对应不同的短网址时，其中一个解决思路，是不做处理，但是如果每个请求都生成一个短网址，并且存储在数据库中，这样会不会撑爆数据库？该如何解决呢？



------







