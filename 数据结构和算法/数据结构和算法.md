# 数据结构和算法

业务开发工程师，CRUD（增删改查） boy 😭😭😭

<u>目标</u>：不能重复地堆砌业务逻辑，要有难度递进，提升能力，写出达到开源水平的框架。

数据结构指的是“一组数据的存储结构”，算法指的是“操作数据的一组方法”。

数据结构是为算法服务的，算法是要作用再特定的数据结构上的。

效率和资源消耗的度量衡--复杂度分析。

<u>总览</u>：

![](/Users/yangzanjie/code/study/数据结构和算法/数据结构和算法.jpg)

------



## 1 常用数据结构和算法

<u>10个数据结构</u>：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie树。

<u>10个算法</u>：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法。

<u>学习技巧</u>：

- 边学边练，适度刷题：建议每周1-2小时时间，自己实现数据结构和算法，刷题适度。
- 多问、多思考、多互动。
- 坚持：打怪升级学习法，设立切实可行的目标，一点点提高。
- 耐心：学习知识，反复迭代，不断沉淀。

------



## 2 复杂度分析一

### 2.1 事后统计法

指通过统计、监控等方式，得到算法执行的时间和占用的你内存大小。

局限性大。

- 测试结果非常依赖测试环境。
- 测试结果受数据规模的影响很大。

### 2.2 大O复杂度表示法

#### 2.2.1 概念

算法执行效率，即代码执行时间（粗略讲）。

`T(n)=O(f(n))`

T(n)表示代码执行的时间；n表示数据的规模大小；f(n)表示每行代码执行的次数总和；O表示代码的执行时间T(n)与f(n)成正比。

<u>大O时间复杂度表示法，并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，故也叫作渐进时间复杂度，简称时间复杂度。</u>

n很大时，公式中的高阶项成为主导，因此只记录最大一个量级。

例如：T(n)=O(n)、T(n)=O(n^2)

#### 2.2.2 时间复杂度分析

- 只关注循环执行次数最多的一段代码

```c++
int cal(int n) {
   int sum = 0;
   int i = 1;
   for (; i <= n; ++i) {
     sum = sum + i;
   }
   return sum;
 }
```

在这里，只关注第4、5行代码，时间复杂度O(n)。

- 加法法则，总复杂度等于量级最大的那段代码的复杂度

```c++
int cal(int n) {
   int sum_1 = 0;
   int p = 1;
   for (; p < 100; ++p) {
     sum_1 = sum_1 + p;
   }

   int sum_2 = 0;
   int q = 1;
   for (; q < n; ++q) {
     sum_2 = sum_2 + q;
   }
 
   int sum_3 = 0;
   int i = 1;
   int j = 1;
   for (; i <= n; ++i) {
     j = 1; 
     for (; j <= n; ++j) {
       sum_3 = sum_3 +  i * j;
     }
   }
 
   return sum_1 + sum_2 + sum_3;
 }
```

sum_1与规模无关，sum_2为O(n)，sum_3为O(n^2)，因此为O(n^2)。

如果 T1(n)=O(f(n))，T2(n)=O(g(n))；

那么T(n)=T1(n)+T2(n)=max(O(f(n))，O(g(n))) =O(max(f(n), g(n))).

- 乘法法则，嵌套代码复杂度等于嵌套内外代码复杂度的乘积

这个好理解，略。

#### 2.2.3 常见时间复杂度案例分析

![](/Users/yangzanjie/code/study/数据结构和算法/复杂度量级.jpg)

多项式量级

非多项式量级：只有俩，O(2^n)和O(n!)

- O(1)

  一般代码，只要不存在循环、递归语句，即使有成千上万行，时间复杂度都是O(1)。

- O(log n)、O(n log n)

  对数阶复杂度。

  ```c++
   i=1;
   while (i <= n)  {
     i = i * 2;
   }
  ```

  变量i值从1开始取，每循环一次乘以2。当大于n时，循环结束，变量i的取值是一个等比数列。一个个列出来，就是2^0、2^1、2^2、2^3、、、2^k、、、、2^x  =  n。求解x=log2n，因此复杂度为O(log2n)。

  变化下

  ```c++
   i=1;
   while (i <= n)  {
     i = i * 3;
   }
  ```

  时间复杂度为O(log3n)。

  因为对数间可以相互转换，log3n=log32 ·log2n，因此log3n=log32 · log2n，log32为常量，基于前面的理论O(Cf(n)) = O(f(n))，可以忽略系数，因次此最终为O(log2n)。

  至于nlogn，即对logn的算法循环执行n遍。

- O(m+n)、O(m*n)

  代码的复杂度由两个数据的规模决定。

  ```c++
  int cal(int m, int n) {
    int sum_1 = 0;
    int i = 1;
    for (; i < m; ++i) {
      sum_1 = sum_1 + i;
    }
  
    int sum_2 = 0;
    int j = 1;
    for (; j < n; ++j) {
      sum_2 = sum_2 + j;
    }
  
    return sum_1 + sum_2;
  }
  ```

  m和n是表示两个数据规模，因为无法事先评估m和n的量级大小，因此不能简单的用加法法则，忽略掉其中一个，所以代码复杂度就是O(m+n)。

  针对这种情况，加法法则变为，T1(m) + T2(n) = O(f(m) + g(n))；

  但是，乘法法则依然有效，T1(m)*T2(n) = O(f(m) * f(n))。

#### 2.2.4 空间复杂度分析

渐进空间复杂度，表示算法的存储空间和数据规模之间的关系。

```c++
void print(int n) {
  int i = 0;
  int[] a = new int[n];
  for (i; i <n; ++i) {
    a[i] = i * i;
  }

  for (i = n-1; i >= 0; --i) {
    print out a[i]
  }
}
```

在第2行申请了一个空间存储变量i，常量阶，跟n没有关系，不考虑。

在第3行申请了一个大小为n的int类型数组，除此之外，没有别的了，因此空间复杂度O(n)。

#### 2.2.5 小结

常见复杂度，从低到高：O(1)、O(logn)、O(n)、O(nlogn)、O(n^2)。

![](/Users/yangzanjie/code/study/数据结构和算法/常见复杂度.jpg)

#### 2.2.6 Think

- 复杂度分析，提供了一个很好的理论分析方法，无关于宿主机平台，提供了对效率的一个大致的认识。
- 针对不同的宿主机平台，不同的数据集大小，同时需要进行性能测试。
- 需要具有时间和空间分析的思维，为特定应用场景选用适合的算法。

------

## 3 复杂度分析二

最好情况时间复杂度

最坏情况时间复杂度

平均情况时间复杂度

均摊时间复杂度

------

## 4 数组

数组Array：一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。

线性表：数组，链表，队列，栈。

非线性表：二叉树、堆、图等。

数组的“杀手锏”特性：随机访问。

随之而来的代价：删除、插入数据，为保证连续性，需要做大量的数据搬移工作。

针对代价的优化：

- 插入时优化，数组存储没有规律时可用。

- 删除时优化，标记清楚。

  <u>JVM标记清楚算法</u>：大多数主流虚拟机采用可达性分析算法来判断对象是否存活，在标记阶段，会遍历所有GC ROOTS，将所有GC ROOTS可达的对象标记为存活。只有当标记工作完成后，清理工作才会开始。

  <u>不足</u>：

  ​			1、效率问题。标记和清理效率都不高。

  ​			2、空间问题。会产生不连续的内存空间碎片。

数组的访问越界问题。

容器、数组。

数组为何要从0开始：从数组的内存模型看，“下标”最确切的定义是“偏移”，从0开始数组的内存计算公式比从1开始的公式，少一次减法指令，效率更高（基础数据结构，效率优化要做到极致）。

栈：函数体内的局部变量存在栈上，连续压栈，向下增长。

------

## 5 链表

### 5.1 base

经典链表应用场景：LRU缓存淘汰算法。

缓存：提高数据读取性能的技术。如CPU缓存、数据库缓存、浏览器缓存等等。

缓存空间有限，常见缓存淘汰策略：先进先出FIFO、最少使用策略Least Frequency Used--LFU、最近最少使用策略Least Recently Used—LFU。

<u>常用的链表结构</u>

​	单链表

![](/Users/yangzanjie/code/study/数据结构和算法/单链表.jpg)

​	循环链表

![](/Users/yangzanjie/code/study/数据结构和算法/循环链表.jpg)

​	双向链表

![](/Users/yangzanjie/code/study/数据结构和算法/双向链表.jpg)

双向循环链表

![](/Users/yangzanjie/code/study/数据结构和算法/双向循环链表.jpg)

删除操作

- 删除节点中“值等于某个给定值”的结点。

  复杂度O(n)

- 删除给定指针指向的结点。

  单链表O(n)，双向链表O(n)

设计思想，空间换时间。

<u>链表数组性能</u>

![](/Users/yangzanjie/code/study/数据结构和算法/链表数组性能.jpg)

思考：何时使用链表or数组？

数组，简单易用，实现上使用连续的内存空间，可以借助CPU缓存机制，访问效率更高，链表非连续存储，对CPU缓存不友好。

数组，缺点是大小固定，一经声明就要占用整块连续内存空间，如果声明数组过大，可能没有足够的连续内存空间分配，导致内存不足oom。

此外，数组不支持动态扩容，扩容时的数据拷贝十分耗时，而链表天然支持，本身大小并没有限制。

对内存使用苛刻：使用数组，链表会使存储消耗翻倍，对链表频繁的增删，导致内存频繁的申请和释放，容易造成内存碎片。如果是Java语言，会导致频繁的GC。

相比之下，链表更适合插入删除操作频繁的场景，当然实际使用的话，针对实际情况权衡。

### 5.2 如何写好链表

- 技巧一：理解指针或引用的含义

- 技巧二：警惕指针丢失和内存泄漏

- 技巧三：<u>利用哨兵简化实现难度</u>

  针对链表的插入、删除操作，需要对第一个和最后一个结点的情况进行特殊处理。

  带头链表、不带头链表。

  举例：数组，取值为key的下标。

- 技巧四：重点留意边界条件处理

  常用的：

  ​	如果链表为空，ok？

  ​	如果链表只包含一个结点，ok？

  ​	如果链表只包含两个结点，ok？

  ​	逻辑在处理头结点和尾结点时，ok？

  ​	。。。

- 技巧五：举例画图，辅助思考

- 技巧六：多写多练



思考：哨兵简化代码，有什么场景？？？



实现之前，思考时间不要太长，先用能想到的暴力解法试试，此外如果一定时间内，想不出来，google一下。



练习题，LeetCode：206、141、21、19、876

------

## 6 栈



从操作特性上看，栈是一种“操作受限”的线性表，只允许在一端插入和删除数据。

数组实现的栈，顺序栈。

链表实现的栈，链式栈。

时间、空间复杂度：O(1)。

<u>支持动态扩容的顺序栈</u>（参考动态扩容数组的实现），入栈、出栈的时间复杂度分析，最好、最坏时间复杂度，均摊时间复杂度。

<u>栈的应用</u>：

- 函数调用中的应用。
- 表达式求值中的应用：操作数栈，运算符栈。。。

- 在括号匹配中的应用。

  

内存中的“堆栈"和数据中的堆栈：

- 内存，在逻辑上分为三部分，代码区、静态数据区和动态数据区，动态数据区又分为栈区和堆区：

  <u>代码区</u>：存储方法体的二进制代码。高级调度（作业调度）、中级调度（内存调度）、低级调度（进程调度）控制代码区执行代码的切换。

  <u>静态数据区</u>：存储全局变量、静态变量、常量包括final修饰的常量和String常量。系统自动分配和回收。

  <u>栈区</u>：存储运行方法的形参、局部变量、返回值。由系统自动分配和回收。

  <u>堆区</u>：new一个对象的引用或地址存储在栈区，指向该对象存储在堆区中的真实数据。



为什么函数调用要用”栈“来保存临时变量？用其他数据结构不行吗？

- 不一定非要用栈来保存临时变量，只不过如果这个函数的调用符合后进先出的特性，用栈这种数据结构来实现，是最顺理成章的选择。

  从调用函数进入被调用函数，变化的是作用域。从根本上，只要保证每次进入一个新函数，都是一个新的作用域即可。而为了实现这个，用栈很方便。在进入一个新函数时，分配一段栈空间给函数的变量，在函数结束的时候，将栈顶复位，就可以回到调用函数的作用域内。



建议LeetCode: 20,155,232,844,224,682,496.

------



## 7 队列Queue

### base

![](/Users/yangzanjie/code/study/数据结构和算法/队列和栈.jpg)

队列，和栈一样，一种<u>操作受限的线性表数据结构</u>。

<u>**最大特点：先进先出。**</u>

应用广泛：例如循环队列、阻塞队列、并发队列；在很多偏底层系统、框架、中间件的开发中，起着关键性作用，例如高性能队列Disruptor、Linux环形缓存，用了循环并发队列；Java concurrent并发包利用ArrayBlockingQueue来实现公平锁等。

顺序队列：数组实现的。

链式队列：链表实现的。



<u>循环队列</u>：关键是确定好队空和队满的条件。



<u>阻塞队列</u>：队列为空时，从队头取数据会被阻塞，直到有了数据才会返回；队列满时，插入数据的操作会被阻塞，直到队列有空闲位置再插入数据。基于阻塞队列，实现“生产者-消费者模型”。

![](/Users/yangzanjie/code/study/数据结构和算法/阻塞队列.jpg)

提高效率，设置多个“消费者”。

![](/Users/yangzanjie/code/study/数据结构和算法/阻塞队列-多消费者.jpg)

<u>并发队列</u>：线程安全。简单的实现方法，直接在enqueue()、dequeue()方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或读操作。

基于数组的循环数组，利用CAS原子操作，可以实现非常高效的并发队列。（因此循环队列比之链式队列应用更为广泛）



<u>线程池无空闲线程时，请求线程资源时，线程该如何处理？各种策略如何实现？</u>

- 非阻塞处理方式，直接拒绝。

- 阻塞处理方式，将请求排队，等有空闲线程时，取出排队请求继续处理。

  <u>如何存储排队请求？</u>

  希望公平处理排队请求，先进者，先服务，因此Queue适合存储排队请求。

  <u>Queue有基于数组的和基于队列的，有何区别？</u>

  基于队列的，实现一个支持无限排队的无界队列，可能会导致队列过长，请求时间过长，因此针对响应时间敏感的系统，基于链表实现的。。。。不合适。

  基于数组的，队列大小有限，请求超过队列大小时，请求会被拒绝，因此，针对响应时间敏感的系统，比较适合，设置队列大小很有讲究，设置的不合适会导致无法充分利用系统资源、发挥最大性能。



<u>应用</u>：队列可以应用在任何有限资源池中，例如数据库连接池等。



<u>思考</u>：

1. 除了线程池、数据库连接池之外，还有哪些类似的池结构或场景中会用到队列的排队请求呢？

   Ansewr：

   分布式应用中的消息队列，比如kafka也是一种队列；

   

2. 关于如何实现无锁并发队列，这个怎么看？

   Answer：

   考虑使用cas实现无锁队列：入队前获取tail位置，入队时，比较tail位置，是否有发生变化，否，则允许，否则失败。出队则获取head位置，进行cas。



😂😂😂😂吃多了拉，就是队列，吃多了吐，就是栈。

------



## 8 递归

### base



<u>**递归需要满足的三个条件**</u>：

- 一个问题可以分解成几个子问题的解：

  子问题，就是数据规模更小的解。

- 这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样
- 存在递归终止条件



<u>**如何写递归代码？**</u>

关键：写出递推公式，找到终止条件。

![](/Users/yangzanjie/code/study/数据结构和算法/写递归代码的关键.jpg)

**😭😭😭思维误区：只要遇到递归，就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。**



<u>**递归代码要警惕堆栈溢出**</u>

函数使用栈来保存临时变量，每调用一个函数，都会将临时变量封装为栈桢压入内存，等函数执行完才返回，才出栈。而系统栈或者虚拟机栈空间一般都不大，如果递归求解的数据规模很大，调用层次很深，一直压入栈，就会有堆栈溢出的风险。

<u>如何避免？</u>

- 限制递归调用的最大深度
- 看使用情况，是否适合用递归



<u>**警惕重复计算**</u>

![递归重复计算](/Users/yangzanjie/code/study/数据结构和算法/递归重复计算.jpg)

如计算f(5)，需要计算f(4)和f(3)，而计算f(4)需要计算f(2)，在这里需要避免重复计算f(3)。

为了避免重复计算，可以通过 一个数据结构（比如散列表）来保存已经求解过的f(k)。当计算到f(k)时，可以。。。。



<u>**递归有利有弊**</u>

利：表达能力强，代码简洁。

弊：递归代码，需要考虑时间成本（调用函数输了较大时，会积聚成一个客观的时间成本）和空间成本（递归调用，栈。。。），空间复杂度高、有堆栈溢出的风险、存在重复计算、过多的函数调用耗时多等问题。



<u>**如何将递归代码改写为非递归代码**</u>？

。。。



<u>**如何找到“最终推荐人”问题**</u>

![最终推荐人](/Users/yangzanjie/code/study/数据结构和算法/最终推荐人.jpg)

```java
long findRootReferrerId(long actorId) {
  Long referrerId = select referrer_id from [table] where actor_id = actorId;
  if (referrerId == null) return actorId;
  return findRootReferrerId(referrerId);
}

```

上述代码用了递归

但是实际不能在项目中使用：

- 存在堆栈溢出风险
- 如果存在脏数据，会产生无限递归问题

解决方法：

- 限制递归深度
- 检测环的存在，例如A-B-C-A



<u>**好的递归代码调试方法**</u>：

打印日志发现，递归值；

结合条件断点进行调试；

------



## 9 排序

![三类排序算法](/Users/yangzanjie/code/study/数据结构和算法/三类排序算法.jpg)



### 9.1 base & 3个O(n^2)的排序算法



<u>**如何分析一个排序算法**</u>

- 最好情况、最坏情况、平均情况时间复杂度

- 时间复杂度的系数、场数、低阶

  在实际开发中，数据规模可能是10、100、1000这样的规模很小的数据，需要考虑系数。

- 比较次数和交换（或移动）次数

  基于比较的排序算法的执行过程，涉及比较和元素交换移动操作，考虑执行效率时，需要将这个也考虑进去。



**<u>排序算法的内存消耗</u>**

**原地排序**sorted in place，特指空间复杂度是O(1)的排序算法。



**<u>排序算法的稳定性</u>**

比如有一组数据2，9，3，4，8，3，

排序后，2，3，3，4，8，9

若排序后两个3的顺序没有发生改变，则为稳定的排序算法；

若发生变化，则为不稳定的排序算法。

例如电商订单根据下单时间、金额排序。。。



<u>**冒泡排序**</u>

- 只涉及相邻数据的交换操作，只需要常量级的临时空间，空间复杂度是O(1)，是一个原地排序算法。

- 相邻元素大小相等时，不做排序。因此稳定

- 时间复杂度

  最好 O(n)

  最坏 O(n^2)

  平均：引入有序度和逆序度。。。略。。。O(n^2)

  **逆序度=n*(n-1)/2-初识有序度**



<u>**插入排序**</u>

思想：找到数据该插入的位置。

已排序区间和未排序区间。

- 不需要额外的存储空间，原地排序

- 稳定

- 时间复杂度

  最好O(n)

  最坏O(n^2)

  平均：往数组插入一个数据的平均复杂度是O(n)，因此对于一个数组，执行n次，就是O(n^2)



<u>**选择排序**</u>

- 原地排序
- 不稳，每次都要找到最小的值，并交换位置。



<u>**冒泡排序和插入排序的时间复杂度都是O(n^2)，为何插入排序比冒泡排序更受欢迎？**</u>

两者元素交换的次数都是原始数据的逆序度。

```c++
冒泡排序中数据的交换操作：
if (a[j] > a[j+1]) { // 交换
   int tmp = a[j];
   a[j] = a[j+1];
   a[j+1] = tmp;
   flag = true;
}

插入排序中数据的移动操作：
if (a[j] > value) {
  a[j+1] = a[j];  // 数据移动
} else {
  break;
}

```

冒泡排序的数据交换更为复杂，需要3次赋值，而插入排序需要1次。



![冒泡插入选择排序](/Users/yangzanjie/code/study/数据结构和算法/冒泡插入选择排序.jpg)



插入排序的优化，<u>**希尔排序**</u>。



<u>**思考**</u>

若数据存储于链表，三种排序算法还能工作吗？

相应的时间、空间复杂度？

![排序1思考答案](/Users/yangzanjie/code/study/数据结构和算法/排序1思考答案.jpg)

------

### 9.2 归并排序&快速排序

两种都是O(nlogn)的排序

#### 9.2.1 归并排序 Merge Sort

![归并排序分解图](/Users/yangzanjie/code/study/数据结构和算法/归并排序分解图.jpg)

分治思想，分而治之，将一个大问题分解成小的问题来解决，解决小问题，即可解决大问题。

分治一般用递归来实现。

分治是一种解决问题的处理思想，递归是一种编程技巧。

<u>**按前述递归章节，先写出公式：**</u>

```
递推公式：
merge_sort(p…r) = merge(merge_sort(p…q), merge_sort(q+1…r))

终止条件：
p >= r 不用再继续分解
```

（👍👍👍。。。。牛皮）

<u>**进而写出伪代码：**</u>

```
// 归并排序算法, A 是数组，n 表示数组大小
merge_sort(A, n) {
  merge_sort_c(A, 0, n-1)
}

// 递归调用函数
merge_sort_c(A, p, r) {
  // 递归终止条件
  if p >= r  then return

  // 取 p 到 r 之间的中间位置 q
  q = (p+r) / 2
  // 分治递归
  merge_sort_c(A, p, q)
  merge_sort_c(A, q+1, r)
  // 将 A[p...q] 和 A[q+1...r] 合并为 A[p...r]
  merge(A[p...r], A[p...q], A[q+1...r])
}
```

<u>**merge的伪代码**</u>

```
merge(A[p...r], A[p...q], A[q+1...r]) {
  var i := p，j := q+1，k := 0 // 初始化变量 i, j, k
  var tmp := new array[0...r-p] // 申请一个大小跟 A[p...r] 一样的临时数组
  while i<=q AND j<=r do {
    if A[i] <= A[j] {
      tmp[k++] = A[i++] // i++ 等于 i:=i+1
    } else {
      tmp[k++] = A[j++]
    }
  }
  
  // 判断哪个子数组中有剩余的数据
  var start := i，end := q
  if j<=r then start := j, end:=r
  
  // 将剩余的数据拷贝到临时数组 tmp
  while start <= end do {
    tmp[k++] = A[start++]
  }
  
  // 将 tmp 中的数组拷贝回 A[p...r]
  for i:=0 to r-p do {
    A[p+i] = tmp[i]
  }
}
```

（牛皮啊😂😂😂）



<u>**思考😭😭😭😭**</u>

借用上述章节提到过的“哨兵”编程技巧，merge的代码就会很简洁，do it。



<u>**性能分析**</u>

- 稳定性

  稳定性，看merge的处理，若A[p...q], A[q+1...r]中有相同的元素，可以先放A[p...q]中的值，那么归并排序是稳定的。

- 时间复杂度

  涉及递归，分析稍微有点复杂😇。略了。[https://time.geekbang.org/column/article/41913](极客时间-数据结构与算法之美-12排序下)

  十分稳定，在任何情况下，最好、最坏、平均都是O(nlogn)

- 空间复杂度

  看起来非常优秀，快速排序最坏情况时间复杂度O(n^2)，没这个好，但是快排应用更为广泛。

  <u>**”致命“弱点**</u>：不是原地排序算法，在合并两数组时，需要借助额外的存储空间。（<u>**注：**</u>不能用分析时间的思路，来分析空间，因为在合并完成后，申请开辟的空间会被释放掉，在任意时刻，CPU只有一个函数在运行，只会有一个临时的内存空间在使用，该空间不会超过n个数据的大小，所以空间复杂度时O(n)。）



#### 9.2.2 快速排序QuckSort

![快速排序原理](/Users/yangzanjie/code/study/数据结构和算法/快速排序原理.jpg)

分治思想：。。。。直到区间缩小为1。



<u>**递推公式：**</u>

```
递推公式：
quick_sort(p…r) = quick_sort(p…q-1) + quick_sort(q+1, r)

终止条件：
p >= r
```



<u>**递归伪代码：**</u>

```
// 快速排序，A 是数组，n 表示数组的大小
quick_sort(A, n) {
  quick_sort_c(A, 0, n-1)
}
// 快速排序递归函数，p,r 为下标
quick_sort_c(A, p, r) {
  if p >= r then return
  
  q = partition(A, p, r) // 获取分区点
  quick_sort_c(A, p, q-1)
  quick_sort_c(A, q+1, r)
}
```



**<u>分区函数伪代码（为保证是原地排序）</u>**：

```
partition(A, p, r) {
  pivot := A[r]
  i := p
  for j := p to r-1 do {
    if A[j] < pivot {
      swap A[i] with A[j]
      i := i+1
    }
  }
  swap A[i] with A[r]
  return i
```

![快排分区函数图解](/Users/yangzanjie/code/study/数据结构和算法/快排分区函数图解.jpg)

（涉及交换操作，不稳定，例如序列6，8，7，6，3，5，第一次分区后，6的顺序就换了。）



<u>**归并&快排的区别**</u>

![归并&快排的区别](/Users/yangzanjie/code/study/数据结构和算法/归并&快排的区别.jpg)

归并：由下到上，先处理子问题，然后再合并。

快排：由上到下，先分区，再处理子问题。



<u>**快排性能分析**</u>：

- 原地

- 不稳定

- 时间复杂度

  [https://time.geekbang.org/column/article/41913](极客时间-数据结构与算法之美-12排序下)

  如果每次分区，正好等分数据，那么和归并排序是一样的O(nlogn)；

  若极端的看，每次pivot选择最后一个元素，退化为O(n^2)。

  递归树求解，后续将。



<u>**思考**</u>：

如何在O(n)的时间复杂度内查找一个无序数组中的第K大元素？

<u>利用分区的思想</u>

------



## 10 线性排序 Linear Orders

三种时间复杂度O(n)的排序算法：桶排序、计数排序、基数排序。

因为这些算法是非基于比较的排序算法，都不涉及元素之间的比较操作。

### 10.1 桶排序 Bucket Sort

<u>**核心思想**</u>：将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。桶内拍完序之后，再把桶里的数据按照顺序依次取出，组成的序列就是有序的。

<u>**限制**</u>：首先数据要容易划分成m个桶，然后，桶之间要有天然的大小顺序，其次，各个桶之间的分布是比较均匀的。（如果数据都被划分到一个桶里，那就退化为O(nlogn)了。）

<u>**应用**</u>：比较适合在<u>**外部排序**</u>中，所谓外部排序就是，数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中。



### 10.2 计数排序 Counting Sort

（桶排序的一种特殊情况。）

当要排序的n个数据，所处的范围并不大的时候，例如最大值是k，那么就可以将数据划分成k个桶。每个桶内的数据都是相同的，省掉了桶内排序的时间。

利用另一个数组来计数。。。略。。。

限制：计数排序只能用在数据范围不大的场景中，如果数据范围要比排序的数据n大很多，就不适合用计数排序了。而且，计数排序只能给非负整数排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数。



### 10.3 基数排序 Radix Sort

一个排序问题，对10万个手机号码排序。手机号码11位，范围大。

规律：比较号码a、b，如果号码前几位中，a比b大了，那么后几位就不用看了。

实现思路：先按最后一位对手机号码进行排序，然后按倒数第二位，依次类推。

这里按照每位来排序的算法，要求是稳定的，否则无法实现。

这里的每位排序算法，可以用 桶排序或者计数排序，。。。略。

对于位数不一致的数据，可以认为“补齐”到相同长度。

<u>**限制**</u>：对数据有要求，需要可以分割出独立的“位”来比较，而且位之间有递进的关系。除此之a，每一位的数据范围不能太大，要可以用线性算法来排序。

------



## 11 排序优化

<u>**如何实现一个通用的、高性能的排序函数？**</u>



![排序算法回顾](/Users/yangzanjie/code/study/数据结构和算法/排序算法回顾.jpg)



线性排序，对数据有要求，因此不适合。

归并排序和快速排序都是O(nlogn)，但是归并排序不是原地排序，因此也不考虑。

快速排序，最坏情况下，会退化为O(n^2)，因此要对此进行优化。

优化点：分区算法。

- 三数取中法
- 随机法
- 。。。。

------



## 12 二分查找 Binary Search

### 12.1 base

二分查找针对的是一个有序的数据集合，。。。

时间复杂度O(logn)

实现：

循环实现，递归实现。

<u>**局限性**</u>：

- 依赖顺序表结构，简单说就是数组。

  链表的话，随机访问复杂度O(n)

- 针对有序数据。

  若无序，先排序。

  若针对一组静态数据，没有频繁的插入、删除，则可以一次排序，多次二分查找。

  但是，若是数据集合有频繁的插入和删除操作，要保证每次操作之后有序，则在每次二分查找之前，进行排序，维护成本很高。

  因此适用于插入、删除操作不频繁，一次排序，多次查找的场景中。针对动态数据，二分查找不适用。

- 数据量太小，不适合二分查找。

  数据量小时，没必要，顺序遍历足够了。

  此外，若是数据间的比较操作非常耗时，不管数据量大小，都推荐使用二分查找，尽可能减少比较次数。

- 数据量太大，也不适合二分查找。

  二分查找，底层依赖数组这种数据结构，而数组为了支持随机访问的特性，要求内存空间<u>**连续**</u>，对内存的要求比较苛刻。



notice：二分查找的边界问题。



思考：

1、如何在1000万个整数块中快速查找某个整数？

2、如何编程实现“求一个数的平方根”，要求精确到小数点后6位。

3、链表存储的话，二分查找的时间复杂度。



### 12.2 二分查找的变形

<u>**如何快速定位IP对应的省份地址？**</u>

二分查找的变形，查找最后一个小于等于给定值

![二分查找的变形](/Users/yangzanjie/code/study/数据结构和算法/二分查找的变形.jpg)



<u>**notice：对于做工程开发的来说，代码易读懂、没bug，更为重要。**</u>我也这个认为😂😂😂



<u>**二分查找易出bug的地方**</u>：终止条件、区间上下界更新方法、返回值选择。



思考：如果有序数组是一个循环有序数组，例如4,5,6,1,2,3。针对这种情况，如何实现一个求值等于给定值的二分查找算法？

![有序循环数组的二分查询](/Users/yangzanjie/code/study/数据结构和算法/有序循环数组的二分查询.jpg)



------



## 13 跳表 Skip List

<u>**问：为什么Redis一定要用跳表来实现？**</u>



一种动态数据结构（对链表稍加改造）。

可以支持快速的插入、删除、查找操作，不复杂，甚至可以替代红黑树（Red-black tree）。

<u>**跳表：链表加多级索引的结构。**</u>

设计思路：空间换时间。

时间复杂度：O(logn)。

空间复杂度：O(n)。

<u>**notice**</u>：实际开发中，原始链表中存储的很有可能是很大的对象，而索引结点只需要存储关键值和几个指针，并不需要存储对象，因此当对象比索引结点大很多时，索引占用的额外空间就可以忽略了。



<u>**高效的动态插入和删除**</u>

时间复杂度：O(logn)。



<u>**跳表索引动态更新**</u>

如果不更新索引，可能出现两个索引结点之间数据非常多的情况，极端情况下，会退化成单链表。

插入时，选择同事将数据插入到部分索引层中。

通过随机函数决定插入到第几级索引中。

随机函数的选择很有讲究，从概率上讲，需要保证跳表的索引大小和数据大小平衡性，不至于性能过渡退化。



<u>**思考**</u>：如果每三个或者五个结点作为上级索引，对应的在跳表中查找数据的时间复杂度是多少？

------



## 14 散列表 Hash Table

### 14.1 

<u>**问：Word文档中的单词拼写检查功能是如何实现的？**</u>



散列思想

散列表用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来。

![散列表](/Users/yangzanjie/code/study/数据结构和算法/散列表.jpg)

散列函数，又称为哈希算法。

散列冲突解决方法：

- <u>**开放寻址法**</u> 

  线性探测

  二次探测

  双重散列

  <u>**notice**</u>：不管采用哪种探测方法，当散列表中空闲位置不多的时候，散列冲突的概率就会大大提高。为了尽可能保证散列表的操作效率，一般情况下，会尽可能保证散列表中有一定比例的空闲槽位。

  用装载因子load fator表示空位的多少。

  散列表的装载因子=填入表中的元素个数/散列表中的长度

- <u>**链表法**</u>

  更加常用，相比开放寻址，也简单很多。

  ![散列表-链表法](/Users/yangzanjie/code/study/数据结构和算法/散列表-链表法.jpg)



核心问题：<u>**散列函数设计**</u>和<u>**散列冲突解决**</u>。



<u>**思考**</u>：

1、假设我们有10万条URL访问日志，如何按照访问次数给URL排序？

2、有两个字符串数组，每个数组大约有10万条字符串，如何快速找出两个数组中的相同字符串？



### 14.2

<u>**问：如何打造一个工业级水平的散列表？**</u>

来避免散列冲突下，散列表性能急剧下降，并且抵抗散列碰撞攻击。



<u>**如何设计散列函数？**</u>

- 不能太复杂。过于复杂，会消耗很多计算时间。
- 散列函数生成的值要尽可能随机并且均匀分布。这样才能避免或者最小化散列冲突。
- 实际工作中，还要综合考虑各种因素，例如关键字长度、特点、分布、散列表大小等。

一般有，“数据分析法”，直接寻址法，平方取中法，折叠法，随机数法等。



<u>**装载因子过大？**</u>

静态数据集合，好处理，数据已知，可设计出好的散列函数。

动态数据集合，平凡变动，无法预估要加入的数据个数，随着数据慢慢加入，装载因子慢慢变大，如何处理？

<u>**动态扩容**</u>

重新申请一个更大的散列表。复杂。

对于支持动态扩容的散列表，插入操作的时间复杂度是多少？

最好时间复杂度O(1)。

最坏，启动扩容，重新申请内存空间，重新计算哈希位置，O(n)。

摊还分析法，时间复杂度接近最好情况，O(1)。

<u>**动态缩容**</u>

随着删除的数据越来越多，空闲空间越来越多。

装载因子阈值的选择要权衡时间、空间复杂度。



<u>**如何避免低效的扩容？**</u>

一次性扩容耗时过多。

设计思想：将扩容操作穿插在插入操作中，分批次完成。

这期间的查询操作，为了兼容新、老散列表中的数据，先从新的查找，再从老的散列表中查找。

这种实现方式，在任何情况下，插入一个数据的时间复杂度都是O(1)。



<u>**如何选择冲突解决方法？**</u>

开放寻址法和链表法，都很常用。

例如Java中的LinkedHashMap就采用了链表法解决冲突，ThreadLocalMap通过线性探测开放寻址法解决冲突。

<u>**优劣分析**</u>

开放寻址法

- 优点
  1. 无链表，因此能有效利用cpu缓存加快查询速度。
  2. 序列化简单。链表法序列化比较难。
- 缺点
  1. 删除数据比较麻烦，需要特殊标记已删除的数据。
  2. 相对于链表法，开放寻址法所有的数据都存储于一个数组中，冲突的代价更高。因此，装载因子的上限不能太大，比较浪费内存空间。

链表法

- 优点
  1. 对内存的利用率比开放寻址法高，因为链表结点可以在需要的时候创建，并不需要像开放寻址法一样提前申请好。
  2. 对大装载因子的容忍度更高，开放寻址法只能适用于装载因子小于1的情况，接近1时，会有大量的冲突，性能下降剧烈 。而对于链表法来说，只要散列函数的值随机均匀，装载因子即便大于1，也只是链表长度变长，查找效率下降比较少。
- 缺点
  1. 链表需要存指针，因此对于小对象的存储来说，比较消耗内存，有可能让内存翻倍。此外链表的零散分布，对于cpu缓存也是不友好的，对执行效率有一定影响。当然对大对象，存储可以忽略。

对链表法改进，将链表改造为其他更高效的<u>**动态数据结构**</u>，比如跳表、红黑树，这样即使出现散列冲突，极端情况下，所有的数据都散列到一个桶内，退化的散列表的查询时间也只是O(logn)，即动态数据结构的查询时间，可以避免散列碰撞攻击。

<u>**总结：**</u>

基于链表的散列冲突方法，适合存储大对象、大数据量的散列表，而且相比于开放寻址法，更为灵活，支持更多的优化策略，比如用红黄树替代链表。

对于小规模、装载因子不高散列表，比较适用开放寻址法。



<u>**工业级散列表举例分析**</u>

Java中的HashMap分析

1. 初始大小
2. 装载因子和动态扩容
3. 散列冲突的解决方法
4. 散列函数（哈希函数）



回答问题：

何为一个工业级的散列表？应该有哪些特性？

- 支持快速的查询、删除、插入操作
- 内存占用合理
- 性能稳定，极端情况下，散列表性能不会退化到无法接受

如何实现？

- 设计一个合理的散列函数
- 定义装载因子阈值（合理），设计动态扩容策略（甚至缩容）
- 选择合理的散列冲突解决方法



<u>**思考：**</u>

在熟悉的编程语言中，哪些数据类型是基于散列表实现的？散列函数是如何设计的？散列冲突是通过哪种方法解决的？是否支持动态扩容？



### 14.3

<u>**问：为何散列表经常和链表一起使用？**</u>



<u>**LRU算法介绍**</u>

当要缓存某个数据时，先在链表中查找这个数据，若没有找到，直接在链表尾部插入这个数据，此时若缓存已满，还需将链表头部的数据删除；如果找到了，则将它移动到链表的尾部。



<u>**缓存 cache 特性**</u>

1. 插入一个数据
2. 删除一个数据
3. 查询一个数据

![散列表-双向循环链表组合](/Users/yangzanjie/code/study/数据结构和算法/散列表-双向循环链表组合.jpg)

<u>**分析实现略**</u>



<u>**Redis有序集合**</u>

key（键值）----score（分值）

通过key、score分别查询



Java中的LinkedHashMap

是通过双向链表和散列表这两种数据结构组合实现的。



<u>**思考**</u>

1、前述散列表和链表结合使用的例子里，用的都是双向链表，改成单向链表，是否还能正常工作？为什么？

2、假设猎聘网有10万名猎头，每个猎头都可以通过做任务（比如发布职位）来积累积分，然后通过积分来下载简历。假设你是猎聘网的一名工程师，如何在内存中存储这10万个猎头的ID和积分信息，让他能够支持这样的几个操作：

- 根据猎头的ID快速查找、删除、更新、这个猎头的积分信息；
- 查找积分在某个区间的猎头ID列表；
- 查找按照积分从小到大排名在第X位到第Y位之间的猎头ID列表

![散列表和链表组合思考](/Users/yangzanjie/code/study/数据结构和算法/散列表和链表组合思考.jpg)

------



## 15 哈希算法 Hash Algorithm

### 15.1

<u>**什么是哈希算法**</u>

将任意长度的二进制串映射为固定长度的二进制串，这个映射规则就是哈希算法，映射后的二进制串就是哈希值。

哈希算法的要求：

- 从哈希值不能反向推导出元数据。（单向哈希算法）
- 对输入数据非常敏感，哪怕原始数据只修改了一个bit，最后得到的哈希值也大不相同。
- 散列冲突的概率要很小，对于不同的原始数据，哈希值想听的概率非常小。
- 哈希算法的执行效率尽量高效，针对较长的文本，也能快速地计算出哈希值。



<u>**哈希算法的应用**</u>

1. <u>**安全加密**</u>：最常用的有MD5-消息摘要算法，SHA-安全散列法，其他的，DES-数据加密标准，AES-高级加密标准。
2. <u>**唯一标识**</u>：对大数据做信息摘要，通过一个较短的二进制编码来标识很大的数据。
3. <u>**数据校验**</u>
4. <u>**散列函数**</u>



字典攻击

防御字典攻击：引入盐salt，与用户的密码组合。



<u>**思考：区块链是一个很多的领域，其底层的实现原理并不复杂，哈希算法是其非常重要的一个理论基础。区块链使用的是哪一种哈希算法，是为了解决什么问题而使用的？**</u>

<u>**Answer**</u>：

区块链是一块块区块组成，每个区块分为两个部分：区块头，和区块体。

区块头保存着自己区块体和上一个区块头的哈希值。

因为这种链式关系和哈希值的唯一性，只要区块链上任意一个区块被修改过，后面所有区块保存的哈希值就不对了。

区块链使用的是SHA256哈希算法，计算哈希值非常耗时，如果要改一个区块，就必须重新计算该区块后面所有区块的哈希值，短时间内几乎不可能做到。



### 15.2

<u>**在分布式系统中的应用**</u>

1. <u>**负载均衡**</u>

   负载均衡算法有很多，比如轮询、随机、加权轮询等。

   如何实现会话粘滞(session sticky)的负载均衡算法？即，在同一个客户端上，在一次会话中的所有请求都路由到同一个服务器上。

   最直接的方法，维护一张表（客户端ip或者会话id与服务器编号映射关系的表），弊端：映射表会随客户增多而增大，浪费内存空间；客户端下线、上线，服务器扩容、缩容会导致映射失效，维护映射表的成本会变大。

   借助哈希算法，对客户端ip或者会话id计算哈希值，将取得的哈希值与服务器列表进行取模运算，最终得到的值就是该被路由到的服务器编号。

2. <u>**数据分片**</u>

   - <u>**如何统计“搜索关键词”出现的次数？**</u>

     假如有1T的日志文件，记录了用户的搜索关键词，如何快速统计出每个关键词的搜索次数，该如何做？

     难点一：数据量大，无法放到一台机器的内存。

     难点二：若只用一台机器处理这么巨大的数据，处理时间会很长。

     解决方案：先对数据进行分片，然后采用多台机器处理的方法，提高数据处理速度。

     具体思路：用n台机器并行处理，从搜索记录的日志文件中，依次读出每个搜索关键词，通过哈希函数计算哈希值，然后再跟n取模，最终得到的值，就是应该被分配到的机器编号。

     这样一来，哈希值相同的搜索关键词就被分配到了同一个机器上。即，同一个搜索关键词被分配到同一个机器上。每个计算器分别计算关键词出现的次数，最终合并起来就是最终的结果。

     这就是MapReduce的基本设计思想。😂😂😂👍👍👍

   - <u>**如何快速判断图片是否在图库中？**</u>

     对小数据量的图片，给每个图片取唯一标识（或者信息标识），然后构建散列表。

     然而对于大数据量的图片（例如一亿张图片），在单台机器上构建散列表是行不通的。

     因此同样要对数据进行分片，采用多机处理。

     ![一亿张图片数据分片处理估算](/Users/yangzanjie/code/study/数据结构和算法/一亿张图片数据分片处理估算.jpg)

3. <u>**分布式存储**</u>

   面对海量数据、海量用户。为了提高数据的读取、写入能力，一般都采用分布式的方式来存储数据，例如分布式缓存。

   <u>**如何决定将哪个数据放到哪个机器上？**</u>

   借用数据分片的思想。

   但是随着数据增多，需要扩容。此时取模运算结果会发生变化。因此所有数据需要重新计算哈希值，然后重新搬到正确的机器上。这就相当于，缓存中的数据一下子都失效了。所有的数据请求都会穿透缓存，直接去请求数据库。这样可能发生雪崩效应，压垮数据库。

   因此，需要一种方法，使得新加入一个机器后，不需要做大量的数据搬移。

   *<u>**一致性哈希算法**</u>*

   ![一致性哈希算法](/Users/yangzanjie/code/study/数据结构和算法/一致性哈希算法.jpg)

[](https://zh.wikipedia.org/wiki/%E4%B8%80%E8%87%B4%E5%93%88%E5%B8%8C)

[](https://www.jianshu.com/p/570dc8913c20)



<u>**思考：哈希算法还有很多应用，例如网络协议中的CRC校验、GIT commit id等等，除了这些，还有哪些用到了哈希算法？**</u>

------



## 16 二叉树

### 16.1 树、二叉树

非线性表结构

<u>**问题：二叉树有哪几种存储方式？什么样的二叉树适合用数组来存储？**</u>



树Tree

![树](/Users/yangzanjie/code/study/数据结构和算法/树.jpg)

概念：父节点，子节点，兄弟结点，根节点，叶子结点（叶节点）；高度Height，深度Depth，层Level

![树的高度、深度、层](/Users/yangzanjie/code/study/数据结构和算法/树的高度、深度、层.jpg)

![树的高度、深度、层-例子](/Users/yangzanjie/code/study/数据结构和算法/树的高度、深度、层-例子.jpg)



<u>**二叉树**</u>

每个节点最多有两个“叉”，即两个子节点。

满二叉树。

完全二叉树。



<u>**如何表示（存储）一颗二叉树？**</u>

1. 链式存储法（基于指针或者引用）

   ![二叉树-链式存储法](/Users/yangzanjie/code/study/数据结构和算法/二叉树-链式存储法.jpg)

2. 顺序存储法

   完全二叉树

   ![二叉树-顺序存储法](/Users/yangzanjie/code/study/数据结构和算法/二叉树-顺序存储法-完全二叉树.jpg)

   非完全二叉树

   ![二叉树-顺序存储法-非完全二叉树](/Users/yangzanjie/code/study/数据结构和算法/二叉树-顺序存储法-非完全二叉树.jpg)

   所以，完全二叉树是最节省内存的一种方式。

   （堆其实就是一种完全二叉树，最常用的存储方式就是数组。）



**二叉树的遍历**

如何将所有的节点遍历打印出来？

经典的方法：前序遍历、中序遍历、后序遍历，前、中、后表示节点与它的左右子树节点遍历打印的先后顺序。

![二叉树遍历-前中后序](/Users/yangzanjie/code/study/数据结构和算法/二叉树遍历-前中后序.jpg)

**<u>前中后序遍历就是一个递归的过程。</u>**

```
前序遍历的递推公式：
preOrder(r) = print r->preOrder(r->left)->preOrder(r->right)

中序遍历的递推公式：
inOrder(r) = inOrder(r->left)->print r->inOrder(r->right)

后序遍历的递推公式：
postOrder(r) = postOrder(r->left)->postOrder(r->right)->print r
```

代码实现：（链式存储的实现）

```c++
void preOrder(Node* root) {
  if (root == null) return;
  print root // 此处为伪代码，表示打印 root 节点
  preOrder(root->left);
  preOrder(root->right);
}

void inOrder(Node* root) {
  if (root == null) return;
  inOrder(root->left);
  print root // 此处为伪代码，表示打印 root 节点
  inOrder(root->right);
}

void postOrder(Node* root) {
  if (root == null) return;
  postOrder(root->left);
  postOrder(root->right);
  print root // 此处为伪代码，表示打印 root 节点
}
```

<u>**二叉树遍历的时间复杂度：**</u>

从前面的遍历顺序图看，每个节点最多被访问两次，所以遍历时间复杂度跟节点个数n成正比，二叉树遍历的时间复杂度是O(n)。



数组顺序存储的方式比较适合完全二叉树，其他类型的二叉树比较浪费内存空间。



<u>**思考：**</u>

1. 给定一组数据，比如1，3，5，6，9，10。可以构建出多少种不同的二叉树？
2. 三种遍历方式，前中后序，还有一种遍历方式，按层遍历，如何实现呢？











### 16.2 二叉树查找

### 16.3 平衡二叉树查找、红黑树

### 16.4 递归树

