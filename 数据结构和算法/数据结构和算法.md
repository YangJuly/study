# 数据结构和算法

业务开发工程师，CRUD（增删改查） boy 😭😭😭

<u>目标</u>：不能重复地堆砌业务逻辑，要有难度递进，提升能力，写出达到开源水平的框架。

数据结构指的是“一组数据的存储结构”，算法指的是“操作数据的一组方法”。

数据结构是为算法服务的，算法是要作用再特定的数据结构上的。

效率和资源消耗的度量衡--复杂度分析。

<u>总览</u>：

![](/Users/yangzanjie/code/study/数据结构和算法/数据结构和算法.jpg)

------



## 1 常用数据结构和算法

<u>10个数据结构</u>：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie树。

<u>10个算法</u>：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法。

<u>学习技巧</u>：

- 边学边练，适度刷题：建议每周1-2小时时间，自己实现数据结构和算法，刷题适度。
- 多问、多思考、多互动。
- 坚持：打怪升级学习法，设立切实可行的目标，一点点提高。
- 耐心：学习知识，反复迭代，不断沉淀。

------



## 2 复杂度分析一

### 2.1 事后统计法

指通过统计、监控等方式，得到算法执行的时间和占用的你内存大小。

局限性大。

- 测试结果非常依赖测试环境。
- 测试结果受数据规模的影响很大。

### 2.2 大O复杂度表示法

#### 2.2.1 概念

算法执行效率，即代码执行时间（粗略讲）。

`T(n)=O(f(n))`

T(n)表示代码执行的时间；n表示数据的规模大小；f(n)表示每行代码执行的次数总和；O表示代码的执行时间T(n)与f(n)成正比。

<u>大O时间复杂度表示法，并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，故也叫作渐进时间复杂度，简称时间复杂度。</u>

n很大时，公式中的高阶项成为主导，因此只记录最大一个量级。

例如：T(n)=O(n)、T(n)=O(n^2)

#### 2.2.2 时间复杂度分析

- 只关注循环执行次数最多的一段代码

```c++
int cal(int n) {
   int sum = 0;
   int i = 1;
   for (; i <= n; ++i) {
     sum = sum + i;
   }
   return sum;
 }
```

在这里，只关注第4、5行代码，时间复杂度O(n)。

- 加法法则，总复杂度等于量级最大的那段代码的复杂度

```c++
int cal(int n) {
   int sum_1 = 0;
   int p = 1;
   for (; p < 100; ++p) {
     sum_1 = sum_1 + p;
   }

   int sum_2 = 0;
   int q = 1;
   for (; q < n; ++q) {
     sum_2 = sum_2 + q;
   }
 
   int sum_3 = 0;
   int i = 1;
   int j = 1;
   for (; i <= n; ++i) {
     j = 1; 
     for (; j <= n; ++j) {
       sum_3 = sum_3 +  i * j;
     }
   }
 
   return sum_1 + sum_2 + sum_3;
 }
```

sum_1与规模无关，sum_2为O(n)，sum_3为O(n^2)，因此为O(n^2)。

如果 T1(n)=O(f(n))，T2(n)=O(g(n))；

那么T(n)=T1(n)+T2(n)=max(O(f(n))，O(g(n))) =O(max(f(n), g(n))).

- 乘法法则，嵌套代码复杂度等于嵌套内外代码复杂度的乘积

这个好理解，略。

#### 2.2.3 常见时间复杂度案例分析

![](/Users/yangzanjie/code/study/数据结构和算法/复杂度量级.jpg)

多项式量级

非多项式量级：只有俩，O(2^n)和O(n!)

- O(1)

  一般代码，只要不存在循环、递归语句，即使有成千上万行，时间复杂度都是O(1)。

- O(log n)、O(n log n)

  对数阶复杂度。

  ```c++
   i=1;
   while (i <= n)  {
     i = i * 2;
   }
  ```

  变量i值从1开始取，每循环一次乘以2。当大于n时，循环结束，变量i的取值是一个等比数列。一个个列出来，就是2^0、2^1、2^2、2^3、、、2^k、、、、2^x  =  n。求解x=log2n，因此复杂度为O(log2n)。

  变化下

  ```c++
   i=1;
   while (i <= n)  {
     i = i * 3;
   }
  ```

  时间复杂度为O(log3n)。

  因为对数间可以相互转换，log3n=log32 ·log2n，因此log3n=log32 · log2n，log32为常量，基于前面的理论O(Cf(n)) = O(f(n))，可以忽略系数，因次此最终为O(log2n)。

  至于nlogn，即对logn的算法循环执行n遍。

- O(m+n)、O(m*n)

  代码的复杂度由两个数据的规模决定。

  ```c++
  int cal(int m, int n) {
    int sum_1 = 0;
    int i = 1;
    for (; i < m; ++i) {
      sum_1 = sum_1 + i;
    }
  
    int sum_2 = 0;
    int j = 1;
    for (; j < n; ++j) {
      sum_2 = sum_2 + j;
    }
  
    return sum_1 + sum_2;
  }
  ```

  m和n是表示两个数据规模，因为无法事先评估m和n的量级大小，因此不能简单的用加法法则，忽略掉其中一个，所以代码复杂度就是O(m+n)。

  针对这种情况，加法法则变为，T1(m) + T2(n) = O(f(m) + g(n))；

  但是，乘法法则依然有效，T1(m)*T2(n) = O(f(m) * f(n))。

#### 2.2.4 空间复杂度分析

渐进空间复杂度，表示算法的存储空间和数据规模之间的关系。

```c++
void print(int n) {
  int i = 0;
  int[] a = new int[n];
  for (i; i <n; ++i) {
    a[i] = i * i;
  }

  for (i = n-1; i >= 0; --i) {
    print out a[i]
  }
}
```

在第2行申请了一个空间存储变量i，常量阶，跟n没有关系，不考虑。

在第3行申请了一个大小为n的int类型数组，除此之外，没有别的了，因此空间复杂度O(n)。

#### 2.2.5 小结

常见复杂度，从低到高：O(1)、O(logn)、O(n)、O(nlogn)、O(n^2)。

![](/Users/yangzanjie/code/study/数据结构和算法/常见复杂度.jpg)

#### 2.2.6 Think

- 复杂度分析，提供了一个很好的理论分析方法，无关于宿主机平台，提供了对效率的一个大致的认识。
- 针对不同的宿主机平台，不同的数据集大小，同时需要进行性能测试。
- 需要具有时间和空间分析的思维，为特定应用场景选用适合的算法。

------

## 3 复杂度分析二

最好情况时间复杂度

最坏情况时间复杂度

平均情况时间复杂度

均摊时间复杂度

------

## 4 数组

数组Array：一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。

线性表：数组，链表，队列，栈。

非线性表：二叉树、堆、图等。

数组的“杀手锏”特性：随机访问。

随之而来的代价：删除、插入数据，为保证连续性，需要做大量的数据搬移工作。

针对代价的优化：

- 插入时优化，数组存储没有规律时可用。

- 删除时优化，标记清楚。

  <u>JVM标记清楚算法</u>：大多数主流虚拟机采用可达性分析算法来判断对象是否存活，在标记阶段，会遍历所有GC ROOTS，将所有GC ROOTS可达的对象标记为存活。只有当标记工作完成后，清理工作才会开始。

  <u>不足</u>：

  ​			1、效率问题。标记和清理效率都不高。

  ​			2、空间问题。会产生不连续的内存空间碎片。

数组的访问越界问题。

容器、数组。

数组为何要从0开始：从数组的内存模型看，“下标”最确切的定义是“偏移”，从0开始数组的内存计算公式比从1开始的公式，少一次减法指令，效率更高（基础数据结构，效率优化要做到极致）。

栈：函数体内的局部变量存在栈上，连续压栈，向下增长。

------

## 5 链表

### 5.1 base

经典链表应用场景：LRU缓存淘汰算法。

缓存：提高数据读取性能的技术。如CPU缓存、数据库缓存、浏览器缓存等等。

缓存空间有限，常见缓存淘汰策略：先进先出FIFO、最少使用策略Least Frequency Used--LFU、最近最少使用策略Least Recently Used—LFU。

<u>常用的链表结构</u>

​	单链表

![](/Users/yangzanjie/code/study/数据结构和算法/单链表.jpg)

​	循环链表

![](/Users/yangzanjie/code/study/数据结构和算法/循环链表.jpg)

​	双向链表

![](/Users/yangzanjie/code/study/数据结构和算法/双向链表.jpg)

双向循环链表

![](/Users/yangzanjie/code/study/数据结构和算法/双向循环链表.jpg)

删除操作

- 删除节点中“值等于某个给定值”的结点。

  复杂度O(n)

- 删除给定指针指向的结点。

  单链表O(n)，双向链表O(n)

设计思想，空间换时间。

<u>链表数组性能</u>

![](/Users/yangzanjie/code/study/数据结构和算法/链表数组性能.jpg)

思考：何时使用链表or数组？

数组，简单易用，实现上使用连续的内存空间，可以借助CPU缓存机制，访问效率更高，链表非连续存储，对CPU缓存不友好。

数组，缺点是大小固定，一经声明就要占用整块连续内存空间，如果声明数组过大，可能没有足够的连续内存空间分配，导致内存不足oom。

此外，数组不支持动态扩容，扩容时的数据拷贝十分耗时，而链表天然支持，本身大小并没有限制。

对内存使用苛刻：使用数组，链表会使存储消耗翻倍，对链表频繁的增删，导致内存频繁的申请和释放，容易造成内存碎片。如果是Java语言，会导致频繁的GC。

相比之下，链表更适合插入删除操作频繁的场景，当然实际使用的话，针对实际情况权衡。

### 5.2 如何写好链表

- 技巧一：理解指针或引用的含义

- 技巧二：警惕指针丢失和内存泄漏

- 技巧三：<u>利用哨兵简化实现难度</u>

  针对链表的插入、删除操作，需要对第一个和最后一个结点的情况进行特殊处理。

  带头链表、不带头链表。

  举例：数组，取值为key的下标。

- 技巧四：重点留意边界条件处理

  常用的：

  ​	如果链表为空，ok？

  ​	如果链表只包含一个结点，ok？

  ​	如果链表只包含两个结点，ok？

  ​	逻辑在处理头结点和尾结点时，ok？

  ​	。。。

- 技巧五：举例画图，辅助思考

- 技巧六：多写多练



思考：哨兵简化代码，有什么场景？？？



实现之前，思考时间不要太长，先用能想到的暴力解法试试，此外如果一定时间内，想不出来，google一下。



练习题，LeetCode：206、141、21、19、876

------

## 6 栈



从操作特性上看，栈是一种“操作受限”的线性表，只允许在一端插入和删除数据。

数组实现的栈，顺序栈。

链表实现的栈，链式栈。

时间、空间复杂度：O(1)。

<u>支持动态扩容的顺序栈</u>（参考动态扩容数组的实现），入栈、出栈的时间复杂度分析，最好、最坏时间复杂度，均摊时间复杂度。

<u>栈的应用</u>：

- 函数调用中的应用。
- 表达式求值中的应用：操作数栈，运算符栈。。。

- 在括号匹配中的应用。

  

内存中的“堆栈"和数据中的堆栈：

- 内存，在逻辑上分为三部分，代码区、静态数据区和动态数据区，动态数据区又分为栈区和堆区：

  <u>代码区</u>：存储方法体的二进制代码。高进调度（作业调度）、中级调度（内存调度）、低级调度（进程调度）控制代码区执行代码的切换。

  <u>静态数据区</u>：存储全局变量、静态变量、常量包括final修饰的常量和String常量。系统自动分配和回收。

  <u>栈区</u>：存储运行方法的形参、局部变量、返回值。由系统自动分配和回收。

  <u>堆区</u>：new一个对象的引用或地址存储在栈区，指向该对象存储在堆区中的真实数据。



为什么函数调用要用”栈“来保存临时变量？用其他数据结构不行吗？

- 不一定非要用栈来保存临时变量，只不过如果这个函数的调用符合后进先出的特性，用栈这种数据结构来实现，是最顺理成章的选择。

  从调用函数进入被调用函数，变化的是作用域。从根本上，只要保证每次进入一个新函数，都是一个新的作用域即可。而为了实现这个，用栈很方便。在进入一个新函数时，分配一段栈空间给函数的变量，在函数结束的时候，将栈顶复位，就可以回到调用函数的作用域内。



建议LeetCode: 20,155,232,844,224,682,496.

------



## 7 队列Queue

### base

![](/Users/yangzanjie/code/study/数据结构和算法/队列和栈.jpg)

队列，和栈一样，一种<u>操作受限的线性表数据结构</u>。

<u>**最大特点：先进先出。**</u>

应用广泛：例如循环队列、阻塞队列、并发队列；在很多偏底层系统、框架、中间件的开发中，起着关键性作用，例如高性能队列Disruptor、Linux环形缓存，用了循环并发队列；Java concurrent并发包利用ArrayBlockingQueue来实现公平锁等。

顺序队列：数组实现的。

链式队列：链表实现的。



<u>循环队列</u>：关键是确定好队空和队满的条件。



<u>阻塞队列</u>：队列为空时，从队头取数据会被阻塞，直到有了数据才会返回；队列满时，插入数据的操作会被阻塞，直到队列有空闲位置再插入数据。基于阻塞队列，实现“生产者-消费者模型”。

![](/Users/yangzanjie/code/study/数据结构和算法/阻塞队列.jpg)

提高效率，设置多个“消费者”。

![](/Users/yangzanjie/code/study/数据结构和算法/阻塞队列-多消费者.jpg)

<u>并发队列</u>：线程安全。简单的实现方法，直接在enqueue()、dequeue()方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或读操作。

基于数组的循环数组，利用CAS原子操作，可以实现非常高效的并发队列。（因此循环队列比之链式队列应用更为广泛）



<u>线程池无空闲线程时，请求线程资源时，线程该如何处理？各种策略如何实现？</u>

- 非阻塞处理方式，直接拒绝。

- 阻塞处理方式，将请求排队，等有空闲线程时，取出排队请求继续处理。

  <u>如何存储排队请求？</u>

  希望公平处理排队请求，先进者，先服务，因此Queue适合存储排队请求。

  <u>Queue有基于数组的和基于队列的，有何区别？</u>

  基于队列的，实现一个支持无限排队的无界队列，可能会导致队列过长，请求时间过长，因此针对响应时间敏感的系统，基于链表实现的。。。。不合适。

  基于数组的，队列大小有限，请求超过队列大小时，请求会被拒绝，因此，针对响应时间敏感的系统，比较适合，设置队列大小很有讲究，设置的不合适会导致无法充分利用系统资源、发挥最大性能。



<u>应用</u>：队列可以应用在任何有限资源池中，例如数据库连接池等。



<u>思考</u>：

1. 除了线程池、数据库连接池之外，还有哪些类似的池结构或场景中会用到队列的排队请求呢？

   Ansewr：

   分布式应用中的消息队列，比如kafka也是一种队列；

   

2. 关于如何实现无锁并发队列，这个怎么看？

   Answer：

   考虑使用cas实现无锁队列：入队前获取tail位置，入队时，比较tail位置，是否有发生变化，否，则允许，否则失败。出队则获取head位置，进行cas。



😂😂😂😂吃多了拉，就是队列，吃多了吐，就是栈。

------



## 8 递归

### base



<u>**递归需要满足的三个条件**</u>：

- 一个问题可以分解成几个子问题的解：

  子问题，就是数据规模更小的解。

- 这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样
- 存在递归终止条件



<u>**如何写递归代码？**</u>

关键：写出递推公式，找到终止条件。

![](/Users/yangzanjie/code/study/数据结构和算法/写递归代码的关键.jpg)

**😭😭😭思维误区：只要遇到递归，就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。**



<u>**递归代码要警惕堆栈溢出**</u>

函数使用栈来保存临时变量，每调用一个函数，都会将临时变量封装为栈桢压入内存，等函数执行完才返回，才出栈。而系统栈或者虚拟机栈空间一般都不大，如果递归求解的数据规模很大，调用层次很深，一直压入栈，就会有堆栈溢出的风险。

<u>如何避免？</u>

- 限制递归调用的最大深度
- 看使用情况，是否适合用递归



<u>**警惕重复计算**</u>

![递归重复计算](/Users/yangzanjie/code/study/数据结构和算法/递归重复计算.jpg)

如计算f(5)，需要计算f(4)和f(3)，而计算f(4)需要计算f(2)，在这里需要避免重复计算f(3)。

为了避免重复计算，可以通过 一个数据结构（比如散列表）来保存已经求解过的f(k)。当计算到f(k)时，可以。。。。



<u>**递归有利有弊**</u>

利：表达能力强，代码简洁。

弊：递归代码，需要考虑时间成本（调用函数输了较大时，会积聚成一个客观的时间成本）和空间成本（递归调用，栈。。。），空间复杂度高、有堆栈溢出的风险、存在重复计算、过多的函数调用耗时多等问题。



<u>**如何将递归代码改写为非递归代码**</u>？

。。。



<u>**如何找到“最终推荐人”问题**</u>

![最终推荐人](/Users/yangzanjie/code/study/数据结构和算法/最终推荐人.jpg)

```java
long findRootReferrerId(long actorId) {
  Long referrerId = select referrer_id from [table] where actor_id = actorId;
  if (referrerId == null) return actorId;
  return findRootReferrerId(referrerId);
}

```

上述代码用了递归

但是实际不能在项目中使用：

- 存在堆栈溢出风险
- 如果存在脏数据，会产生无限递归问题

解决方法：

- 限制递归深度
- 检测环的存在，例如A-B-C-A



<u>**好的递归代码调试方法**</u>：

打印日志发现，递归值；

结合条件断点进行调试；

------



## 9 排序

![三类排序算法](/Users/yangzanjie/code/study/数据结构和算法/三类排序算法.jpg)



### 9.1 base & 3个O(n^2)的排序算法



<u>**如何分析一个排序算法**</u>

- 最好情况、最坏情况、平均情况时间复杂度

- 时间复杂度的系数、场数、低阶

  在实际开发中，数据规模可能是10、100、1000这样的规模很小的数据，需要考虑系数。

- 比较次数和交换（或移动）次数

  基于比较的排序算法的执行过程，涉及比较和元素交换移动操作，考虑执行效率时，需要将这个也考虑进去。



**<u>排序算法的内存消耗</u>**

**原地排序**sorted in place，特指空间复杂度是O(1)的排序算法。



**<u>排序算法的稳定性</u>**

比如有一组数据2，9，3，4，8，3，

排序后，2，3，3，4，8，9

若排序后两个3的顺序没有发生改变，则为稳定的排序算法；

若发生变化，则为不稳定的排序算法。

例如电商订单根据下单时间、金额排序。。。



<u>**冒泡排序**</u>

- 只涉及相邻数据的交换操作，只需要常量级的临时空间，空间复杂度是O(1)，是一个原地排序算法。

- 相邻元素大小相等时，不做排序。因此稳定

- 时间复杂度

  最好 O(n)

  最坏 O(n^2)

  平均：引入有序度和逆序度。。。略。。。O(n^2)

  **逆序度=n*(n-1)/2-初识有序度**



<u>**插入排序**</u>

思想：找到数据该插入的位置。

已排序区间和未排序区间。

- 不需要额外的存储空间，原地排序

- 稳定

- 时间复杂度

  最好O(n)

  最坏O(n^2)

  平均：往数组插入一个数据的平均复杂度是O(n)，因此对于一个数组，执行n次，就是O(n^2)



<u>**选择排序**</u>

- 原地排序
- 不稳，每次都要找到最小的值，并交换位置。



<u>**冒泡排序和插入排序的时间复杂度都是O(n^2)，为何插入排序比冒泡排序更受欢迎？**</u>

两者元素交换的次数都是原始数据的逆序度。

```c++
冒泡排序中数据的交换操作：
if (a[j] > a[j+1]) { // 交换
   int tmp = a[j];
   a[j] = a[j+1];
   a[j+1] = tmp;
   flag = true;
}

插入排序中数据的移动操作：
if (a[j] > value) {
  a[j+1] = a[j];  // 数据移动
} else {
  break;
}

```

冒泡排序的数据交换更为复杂，需要3次赋值，而插入排序需要1次。



![冒泡插入选择排序](/Users/yangzanjie/code/study/数据结构和算法/冒泡插入选择排序.jpg)



插入排序的优化，<u>**希尔排序**</u>。



<u>**思考**</u>

若数据存储于链表，三种排序算法还能工作吗？

相应的时间、空间复杂度？

![排序1思考答案](/Users/yangzanjie/code/study/数据结构和算法/排序1思考答案.jpg)

------

### 9.2 归并排序&快速排序

两种都是O(nlogn)的排序

#### 9.2.1 归并排序 Merge Sort

![归并排序分解图](/Users/yangzanjie/code/study/数据结构和算法/归并排序分解图.jpg)

分治思想，分而治之，将一个大问题分解成小的问题来解决，解决小问题，即可解决大问题。

分治一般用递归来实现。

分治是一种解决问题的处理思想，递归是一种编程技巧。

<u>**按前述递归章节，先写出公式：**</u>

```
递推公式：
merge_sort(p…r) = merge(merge_sort(p…q), merge_sort(q+1…r))

终止条件：
p >= r 不用再继续分解
```

（👍👍👍。。。。牛皮）

<u>**进而写出伪代码：**</u>

```
// 归并排序算法, A 是数组，n 表示数组大小
merge_sort(A, n) {
  merge_sort_c(A, 0, n-1)
}

// 递归调用函数
merge_sort_c(A, p, r) {
  // 递归终止条件
  if p >= r  then return

  // 取 p 到 r 之间的中间位置 q
  q = (p+r) / 2
  // 分治递归
  merge_sort_c(A, p, q)
  merge_sort_c(A, q+1, r)
  // 将 A[p...q] 和 A[q+1...r] 合并为 A[p...r]
  merge(A[p...r], A[p...q], A[q+1...r])
}
```

<u>**merge的伪代码**</u>

```
merge(A[p...r], A[p...q], A[q+1...r]) {
  var i := p，j := q+1，k := 0 // 初始化变量 i, j, k
  var tmp := new array[0...r-p] // 申请一个大小跟 A[p...r] 一样的临时数组
  while i<=q AND j<=r do {
    if A[i] <= A[j] {
      tmp[k++] = A[i++] // i++ 等于 i:=i+1
    } else {
      tmp[k++] = A[j++]
    }
  }
  
  // 判断哪个子数组中有剩余的数据
  var start := i，end := q
  if j<=r then start := j, end:=r
  
  // 将剩余的数据拷贝到临时数组 tmp
  while start <= end do {
    tmp[k++] = A[start++]
  }
  
  // 将 tmp 中的数组拷贝回 A[p...r]
  for i:=0 to r-p do {
    A[p+i] = tmp[i]
  }
}
```

（牛皮啊😂😂😂）



<u>**思考😭😭😭😭**</u>

借用上述章节提到过的“哨兵”编程技巧，merge的代码就会很简洁，do it。



<u>**性能分析**</u>

- 稳定性

  稳定性，看merge的处理，若A[p...q], A[q+1...r]中有相同的元素，可以先放A[p...q]中的值，那么归并排序是稳定的。

- 时间复杂度

  涉及递归，分析稍微有点复杂😇。略了。[https://time.geekbang.org/column/article/41913](极客时间-数据结构与算法之美-12排序下)

  十分稳定，在任何情况下，最好、最坏、平均都是O(nlogn)

- 空间复杂度

  看起来非常优秀，快速排序最坏情况时间复杂度O(n^2)，没这个好，但是快排应用更为广泛。

  <u>**”致命“弱点**</u>：不是原地排序算法，在合并两数组时，需要借助额外的存储空间。（<u>**注：**</u>不能用分析时间的思路，来分析空间，因为在合并完成后，申请开辟的空间会被释放掉，在任意时刻，CPU只有一个函数在运行，只会有一个临时的内存空间在使用，该空间不会超过n个数据的大小，所以空间复杂度时O(n)。）



#### 9.2.2 快速排序QuckSort

![快速排序原理](/Users/yangzanjie/code/study/数据结构和算法/快速排序原理.jpg)

分治思想：。。。。直到区间缩小为1。



<u>**递推公式：**</u>

```
递推公式：
quick_sort(p…r) = quick_sort(p…q-1) + quick_sort(q+1, r)

终止条件：
p >= r
```



<u>**递归伪代码：**</u>

```
// 快速排序，A 是数组，n 表示数组的大小
quick_sort(A, n) {
  quick_sort_c(A, 0, n-1)
}
// 快速排序递归函数，p,r 为下标
quick_sort_c(A, p, r) {
  if p >= r then return
  
  q = partition(A, p, r) // 获取分区点
  quick_sort_c(A, p, q-1)
  quick_sort_c(A, q+1, r)
}
```



**<u>分区函数伪代码（为保证是原地排序）</u>**：

```
partition(A, p, r) {
  pivot := A[r]
  i := p
  for j := p to r-1 do {
    if A[j] < pivot {
      swap A[i] with A[j]
      i := i+1
    }
  }
  swap A[i] with A[r]
  return i
```

![快排分区函数图解](/Users/yangzanjie/code/study/数据结构和算法/快排分区函数图解.jpg)

（涉及交换操作，不稳定，例如序列6，8，7，6，3，5，第一次分区后，6的顺序就换了。）



<u>**归并&快排的区别**</u>

![归并&快排的区别](/Users/yangzanjie/code/study/数据结构和算法/归并&快排的区别.jpg)

归并：由下到上，先处理子问题，然后再合并。

快排：由上到下，先分区，再处理子问题。



<u>**快排性能分析**</u>：

- 原地

- 不稳定

- 时间复杂度

  [https://time.geekbang.org/column/article/41913](极客时间-数据结构与算法之美-12排序下)

  如果每次分区，正好等分数据，那么和归并排序是一样的O(nlogn)；

  若极端的看，每次pivot选择最后一个元素，退化为O(n^2)。

  递归树求解，后续将。



<u>**思考**</u>：

如何在O(n)的时间复杂度内查找一个无序数组中的第K大元素？

<u>利用分区的思想</u>





 0  1  2  3  4  5

s 0

mid 2 

e 5